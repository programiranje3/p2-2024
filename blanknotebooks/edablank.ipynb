{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Exploratory data analysis\n",
    "Introduction to exploratory data analysis (EDA)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "EDA is an approach to analyzing datasets to summarize their main characteristics, often with visual methods. EDA is used for seeing what the data can tell us before the modeling task [(source 1)](https://chartio.com/learn/data-analytics/what-is-exploratory-data-analysis/). It is used to explore the data, find different patterns, relations, and anomalies in the data using some statistical graphs and other visualization techniques, and possibly formulate hypotheses that could lead to new data collection and experiments [(source 2)](https://www.analyticsvidhya.com/blog/2021/08/how-to-perform-exploratory-data-analysis-a-guide-for-beginners/). More specifically, EDA enables analysts to:\n",
    "1. get maximum insights from a data set\n",
    "2. uncover underlying structure\n",
    "3. extract important variables from the dataset\n",
    "4. detect outliers and anomalies (if any)\n",
    "5. test underlying assumptions\n",
    "6. determine the optimal factor settings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## EDA steps and tools\n",
    "Practical steps in conducting EDA and frequently used EDA tools.\n",
    "Based on *pandas2020-main.Sales_Analysis_Pandas_P3_tutorial.ipynb* and *pandas2020-main.TED_Talks_Pandas_P3_tutorial.ipynb*.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Based on [this](https://stackoverflow.com/a/22149930/1899061), in all computations, `axis=...` refers to the axis **along which** the computation is done. By default, `axis=0`. This is consistent with the `numpy.mean` usage when axis is specified explicitly (in `numpy.mean`, `axis==None` by default, which computes the mean value over the flattened array), in which `axis=0` along the rows (namely, index in pandas), and `axis=1` along the columns.\n",
    "Note also that that `axis=0` indicates aggregating along rows and `axis=1` indicates aggregating along columns. This is consistent with how we index into a dataframe. In `df.iloc[<row>, <column>]`, `<row>` is in index position 0 and `<column>` is in index position 1. For added clarity, one may choose to specify `axis='index'` (instead of `axis=0`) or `axis='columns'` (instead of `axis=1`).\n",
    "**But**, `axis=0` means each row as a bulk - we manipulate a `pd.DataFrame` inter-row, instead of within-row. Likewise, 1 means each column as a bulk, i.e. we manipulate a `pd.DataFrame` inter-column instead of within-column. For example, `<pd.df>.drop(\"A\", axis=1)` will drop a whole column."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Reading the dataset\n",
    "- `pd.read_csv()`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Initial examination and adaptations\n",
    "- `<pd.df>.shape`, `<pd.df>.head()`, `<pd.df>.tail()`, `<pd.df>.sample()`, `<pd.df>.dtypes`, `<pd.df>.info()`, `<pd.df>.describe()`\n",
    "- `<pd.df>.loc[...]`, `<pd.df>.iloc[...]` - examine individual cells, columns, rows\n",
    "    - `loc` works with conditions and column names, `iloc` with numerical indices\n",
    "    - in both `loc` and `iloc`, multiple columns can be specified as a list of column names, and `:` in each index position means 'all'\n",
    "    - in `iloc`, both index positions can be specified as lists of numeric values\n",
    "- `<pd.df>.columns`, `<pd.df>.columns.values`, `<pd.df>.columns.values.tolist()` (or `<pd.df>.columns.values.to_list()`), `<pd.df>.values`\n",
    "- `<pd.df>.rename({'<column_1 old name>':'<column_1 new name>', '<column_2 old name>':'<column_2 new name>', ...}, axis='columns')`, `<pd.df>.columns = ['<column_1 name>', '<column_2 name>', ...]` (change the names of all columns in <pd.df>)\n",
    "- `ast.literal_eval()` (using Python's *ast* module to transform a string into a literal value, a list, a tuple or any other container object)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Missing values and value counts\n",
    "- `sb.heatmap()`, e.g. `sb.heatmap(<pd.df>.isna(),cbar=False,cmap='viridis')` ([example](https://www.analyticsvidhya.com/blog/2021/08/how-to-perform-exploratory-data-analysis-a-guide-for-beginners/))\n",
    "- `<pd.df>.isna()` (`<pd.df>.isnull()`), `<pd.df>.isna().sum()` (`<pd.df>.isnull().sum`) ([example](https://www.analyticsvidhya.com/blog/2021/08/how-to-perform-exploratory-data-analysis-a-guide-for-beginners/))\n",
    "- `<pd.df>['<column>'].value_counts()` (shows only the rows without NAs (default: dropna=True), check shape)\n",
    "- `<pd.df>['<column>'].value_counts(normalize=True)` (show proportions, rather than frequencies)\n",
    "- `<pd.Series>.dropna(how='all'/'any', inplace=True)` (return a new `<pd.Series>` object with missing values removed)\n",
    "\n",
    "The `cmap` parameter of `sb.heatmap()` denotes a [Matplotlib colormap](https://matplotlib.org/stable/tutorials/colors/colormaps.html#classes-of-colormaps) (`viridis`, `cividis`, `tab20`, `winter`, `BuPu_r`, `ocean`,...)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Examining individual data items, rows and columns\n",
    "- `<pd.df>.sample()`\n",
    "- Simple indexing and fancy indexing: `<pd.df>.iloc[]`, `<pd.df>.loc[]`\n",
    "- `<pd.df>.index`, `<pd.df>.index[<from>:<to>]`, `<pd.df>.reset_index(drop=True, inplace=True)`\n",
    "- Indexing using list of values: `<pd.df>.loc[<pd.df>.<column>.isin(<list of values>)]` (select those observations where the value of `<column>` is in the `<list of values>`)\n",
    "- Indexing in data stats: `<pd.df>.describe().loc['50%', '<column_name>']` (select the median of `<column_name>` from the `<pd.df>` stats computed by `describe()`)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Grouping and sorting data\n",
    "- `<pd.df>['<column>'].unique()`, `<pd.df>['<column>'].nunique()`\n",
    "- `<pd.df>['<column>'].groupby()`, `<pd.df>['<column>'].groupby().get_group()`\n",
    "- `<pd.df>['<column>'].value_counts()`, `<pd.df>['<column>'].value_counts().sort_index()`, `<pd.df>['<column>'].value_counts().sort_index(inplace=True)`\n",
    "- `<pd.df>.sort_values(by='<column name>', ascending=False/True)`\n",
    "- `<pd.df>.groupby('<column>').<another column>.<f()>.sort_values(ascending=False)` (aggregate using function `f()`, e.g. `mean()`)\n",
    "- `<pd.df>.groupby('<column>').<another column>.agg(['<f1 name>', '<f2 name>', ...])` (aggregate using multiple functions, e.g. `mean()`, `count()`,...)\n",
    "\n",
    "If `sort_values()` is used after `agg(['f1 name>', '<f2 name>', ...])` (`agg(['<f1 name>', '<f2 name>', ...]).sort_values(by='<f name>', ascending=False)`), it must be passed one positional argument (`by='<f name>'`) before the optional `ascending=False`.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data transformations\n",
    "- `<pd.df>.describe()`\n",
    "- `pd.to_numeric(<pd.DataFrame object>['<column name>'], errors='coerce')`, `pd.DataFrame.to_numpy()`, `pd.Series.to_numpy()`, `pd.to_datetime()`, ...\n",
    "- `<pd.df>.<column>.apply(<f_name>)` (apply the <f_name> function to all elements of each element of the `<column>`; for example, each element of the `<column>` can be a list of other elements)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Exploring correlations\n",
    "Explore correlations between the (numerical) columns. \n",
    "- `sb.heatmap()`\n",
    "- [Example](https://www.analyticsvidhya.com/blog/2021/08/how-to-perform-exploratory-data-analysis-a-guide-for-beginners/)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data visualization\n",
    "Plot some bargraphs, scatterplots, boxplots,...\n",
    "- [Example](https://www.analyticsvidhya.com/blog/2021/08/how-to-perform-exploratory-data-analysis-a-guide-for-beginners/)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Other\n",
    "[Other interesting ideas and different ways of using the things from above](https://realpython.com/pandas-python-explore-dataset/#exploring-your-dataset) (see the rest from [that article](https://realpython.com/pandas-python-explore-dataset/) as well)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import and configure packages\n",
    "The `%run` magic might not work well in DataSpell, thus the following `import` statements are copied here from *import_packages.ipynb*:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%run \"../notebooks/import_packages.ipynb\""
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": 0
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # %load_ext autoreload\n",
    "# # %autoreload 2\n",
    "# \n",
    "# %matplotlib inline\n",
    "# \n",
    "# # %config IPCompleter.greedy=True\n",
    "# \n",
    "# import numpy as np\n",
    "# import matplotlib as mpl\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.style.use('classic')\n",
    "# import pandas as pd\n",
    "# import seaborn as sb\n",
    "# \n",
    "# from plotnine import ggplot, aes, labs, geom_point, geom_line, geom_histogram, theme_xkcd, coord_cartesian, xlim, ylim, xlab, ylab, ggtitle, theme"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Introducing The British Invasion datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Available datasets\n",
    "The British Invasion datasets, located in the *data* folder:\n",
    "* *brit.csv* - complete raw dataset (including data from Spotify, Wikipedia, AllMusic, etc.)\n",
    "* *brit_col_renamed.csv* - same as *brit.csv*, but with column names modified for the sake of consistency\n",
    "* *brit_performers_stripped.csv* - same as *brit_col_renamed.csv*, but with performer names stripped for `\\n` etc.\n",
    "* *brit_titles_stripped* - same as *brit_performers_stripped.csv*, but with song titles rstripped\n",
    "* *attrs.csv* - incomplete raw dataset (some of the attributes from [a Kaggle dataset](https://www.kaggle.com/datasets/saurabhshahane/music-dataset-1950-to-2019))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Read the *csv* file containing one of the available datasets describing The British Invasion songs\n",
    "`pd.read_csv()` returns a `pd.DataFrame` object.\n",
    "\n",
    "As for specifying the path of the dataset properly, see [this](https://stackoverflow.com/questions/35384358/how-to-open-my-files-in-data-folder-with-pandas-using-relative-path) (more specifically, **both** [this](https://stackoverflow.com/a/35384414/1899061) and [this](https://stackoverflow.com/a/43600253/1899061))."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Get the songs as a pd.DataFrame object from 'data/brit.csv', \n",
    "# or from '../data/brit.csv', \n",
    "# or '../../data/brit.csv', \n",
    "# or ..., \n",
    "# depending on where the csv file is located\n",
    "\n",
    "# If an int column contains NaN values, read_csv() sets all values to float values, because NaN are internally\n",
    "# represented as float values. To read the int columns as int values and still preserve NaN values where they \n",
    "# exist, see this: https://stackoverflow.com/a/72323514. \n",
    "# The trick is: df = pd.read_csv('file.csv', dtype={'a': 'Int32', 'b': 'Int32'}), assuming that 'a' and 'b' \n",
    "# columns contain int and NaN values."
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Explore the dataset (first steps)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Initial examination and adaptations\n",
    "- `<pd.df>.shape`, `<pd.df>.head()`, `<pd.df>.tail()`, `<pd.df>.sample()`, `<pd.df>.dtypes`, `<pd.df>.info()`, `<pd.df>.describe()`\n",
    "- `<pd.df>.loc[...]`, `<pd.df>.iloc[...]` - examine individual cells, columns, rows\n",
    "    - `loc` works with conditions and column names, `iloc` with numerical indices\n",
    "    - in both `loc` and `iloc`, multiple columns can be specified as a list of column names, and `:` in each index position means 'all'\n",
    "    - in `iloc`, both index positions can be specified as lists of numeric values\n",
    "- `<pd.df>.columns`, `<pd.df>.columns.values`, `<pd.df>.columns.values.tolist()` (or `<pd.df>.columns.values.to_list()`), `<pd.df>.values`\n",
    "- `<pd.df>.rename({'<column_1 old name>':'<column_1 new name>', '<column_2 old name>':'<column_2 new name>', ...}, axis='columns')`, `<pd.df>.columns = ['<column_1 name>', '<column_2 name>', ...]` (change the names of all columns in <pd.df>)\n",
    "- `ast.literal_eval()` (using Python's *ast* module to transform a string into a literal value, a list, a tuple or any other container object)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### A sneak peek into the dataset\n",
    "- `<pd.df>.shape`, `<pd.df>.head()`, `<pd.df>.tail()`, `<pd.df>.sample()`, `<pd.df>.dtypes`, **<u>`<pd.df>.info()`**</u>, `<pd.df>.describe()` (shows descriptive statistics for numerical columns only).\n",
    "\n",
    "When calling `display()` on a method like `<pd.df>.head()`, `<pd.df>.tail()` and `<pd.df>.sample()`, only a certain default number of columns is displayed. To display *all* columns, use `pd.set_option('display.max_columns', None)` first. To display `<n>` columns, use `pd.set_option('display.max_columns', <n>)` first. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### Columns\n",
    "- `<pd.df>.columns`, `<pd.df>.columns.values`, `<pd.df>.columns.values.tolist()` (or `<pd.df>.columns.values.to_list()`), `<pd.df>.values`\n",
    "\n",
    "Show the columns of the `songs` object (which is a `pd.DataFrame` object)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get the columns as a pd.Index object, using <pd.df>.columns\n",
    "\n",
    "# Get the columns as a list, using list(<pd.df>.columns)\n",
    "\n",
    "# Get the columns as a list, using <pd.df>.columns.tolist() or <pd.df>.columns.to_list()\n",
    "\n",
    "# Get the columns as a numpy.ndarray object, using <pd.df>.columns.values or np.array(<pd.df>.columns)\n",
    "\n",
    "# Get the values of all items in the dataset as a numpy.ndarray of sequences of the values in each item, \n",
    "# using <pd.df>.values (the type of both the encompassing and the encompassed sequences is numpy.ndarray)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### Renaming columns\n",
    "- `<pd.df>.rename(columns={'<column_1 old name>':'<column_1 new name>', '<column_2 old name>':'<column_2 new name>', ...}, inplace=True)`, or\n",
    "- `<pd.df>.rename({'<column_1 old name>':'<column_1 new name>', '<column_2 old name>':'<column_2 new name>', ...}, axis='columns', inplace=True)`;\n",
    "- `<pd.df>.columns = ['<column_1 name>', '<column_2 name>', ...]` (change the names of all columns in `<pd.df>`)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Rename the names of some columns\n",
    "\n",
    "# Rename these columns back to their original names\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Save the modified dataset\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### Adapt the data in columns to the usual formats"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Performer - strip everything after the performer name\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Performer - get rid of the 'feat: ' prefix in some performer names\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Save the modified dataset\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": 0
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Title - strip trailing blanks\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Save the modified dataset\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Missing values and value counts\n",
    "- `sb.heatmap()`, e.g. `sb.heatmap(<pd.df>.isna(),cbar=False,cmap='viridis')` ([example](https://www.analyticsvidhya.com/blog/2021/08/how-to-perform-exploratory-data-analysis-a-guide-for-beginners/))\n",
    "- `<pd.df>.isna()` (`<pd.df>.isnull()`), `<pd.df>.isna().sum()` (`<pd.df>.isnull().sum()`) ([example](https://www.analyticsvidhya.com/blog/2021/08/how-to-perform-exploratory-data-analysis-a-guide-for-beginners/))\n",
    "- `<pd.df>['<column>'].value_counts()` (shows only the rows without NAs (default: dropna=True), check shape)\n",
    "- `<pd.df>['<column>'].value_counts(normalize=True)` (show proportions, rather than frequencies)\n",
    "- `<pd.df>.dropna(how='all'/'any', inplace=True)`, `<pd.Series>.dropna(how='all'/'any', inplace=True)` (return a new `<pd.Series>`/`<pd.Series>` object with missing values removed)\n",
    "\n",
    "The `cmap` parameter of `sb.heatmap()` denotes a [Matplotlib colormap](https://matplotlib.org/stable/tutorials/colors/colormaps.html#classes-of-colormaps) (`viridis`, `cividis`, `tab20`, `winter`, `BuPu_r`, `ocean`,...)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# Read the dataset\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Display the heatmap (missing values) of the songs dataset \n",
    "# (demonstrate using sb.heatmap() vs. sb.heatmap();)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "How many missing values are there? (`<pd.df>.isna().sum()` for all columns, `<pd.df>.['<column>'].isna().sum()` for a specific column, `<pd.df>.isna()[['<column1>', 'column2', ...]].sum()` for selected multiple columns; `isnull()` is the same as `isna()`, and `isna()` is used more often).\n",
    "\n",
    "Try also `<pd.df>.isna()`, `<pd.df>.isna()[['<column1>', 'column2', ...]]`, `type(<pd.df>.isna())`, `type(<pd.df>.isna().sum())`, `type(<pd.df>.isna()[['<column1>', 'column2', ...]].sum())`, `<pd.df>.isna().sum().value_counts()`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "How many missing values are there in the columns where there *are* missing values? `<i> = <pd.df>.isna().sum() > 0`, `<pd.df>.isna().sum()[<i>]`. \n",
    "Try also `<i>`, `type(<i>)`, `<i>[<i>]`, `<pd.df>.loc[:, <i>]`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Leave out rows with `np.NaN` values: `<pd.df>.dropna()`, `<pd.df>.<column>.dropna()`, `<pd.df>['<column>'].dropna()`."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "cell_type": "markdown",
   "source": [
    "Show value counts for a dataframe: `<pd.df>.value_counts()`, `<pd.df>.value_counts(normalize=True)`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Show duplicates (if any): `<pd.df>.duplicated()` (keeps the first occurrence by default), `<pd.df>.duplicated(keep=False)` (keeps all occurrences), `<pd.df>.<column>.duplicated()` (find duplicates based on a specific column), `<pd.df>.duplicated(subset=['<column 1>', '<column 2>',...])` (find duplicates based on multiple specific columns). \n",
    "\n",
    "Drop duplicates (if any): `<pd.df>.drop_duplicates(inplace=True)`."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Examining individual data items, rows and columns\n",
    "- `<pd.df>.sample()`\n",
    "- Simple indexing and fancy indexing: `<pd.df>.iloc[]`, `<pd.df>.loc[]`\n",
    "- `<pd.df>.index`, `<pd.df>.index[<from>:<to>]`, `<pd.df>.reset_index(drop=True, inplace=True)`\n",
    "- Indexing using list of values: `<pd.df>.loc[<pd.df>.<column>.isin(<list of values>)]` (select those observations where the value of <column> is in the `<list of values>`)\n",
    "- Indexing in data stats: `<pd.df>.describe().loc['50%', '<column_name>']` (select the median of `<column_name>` from the `<pd.df>` stats computed by `describe()`)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Take a sample of the dataset to get a feeling of what's in there."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "What are the songs that have *some* missing values? \n",
    "Use masking to create the index of such elements; e.g. `<i>`, e.g., `<i> = songs.isna().sum() > 0` and show the type of the result (it's a `pd.Series` object).\n",
    "Display `<i>.index` and `<i>.values`. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the `pd.Series` object `<i>` created in the previous step, select the elements that have the values > 0 (i.e., the names of the columns that have some `NaN` values) - `<i>[<i>.values > 0]`, `<pd.df>.isna().sum()[i]`. \n",
    "Also, from the `<pd.df>` select a subset with only those columns that have *some* `NaN` values - `<pd.df>.loc[:, <i>]`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "How many `NaN`s are there in each column that has `NaN`s? `<pd.df>.isna().sum()[i]`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "From a `<pd.df>` select all rows that have *some* missing values: `<pd.df>[<pd.df>.isna().any(axis=1)]`, `<pd.df>.loc[<pd.df>.isna().any(axis=1)]`, `<pd.df>.loc[<pd.df>.isna().any(axis=1), :]`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-10T15:01:36.662285Z",
     "start_time": "2023-11-10T15:01:36.660780900Z"
    }
   }
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Select rows based on column conditions: `<pd.df>.loc[<pd.df>.<column 1> == <...>]`, `<pd.df>.loc[(<pd.df>.<column 1> == <...>) & (<pd.df>.<column 2> == <...>)]`, etc. Notice the use of `&`, not `and`."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "cell_type": "markdown",
   "source": [
    "What are the rows that have missing values in a specific column of a `<pd.df>`? For example, what are the songs with missing `Duration` values?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using `isna()`, `loc[]`, `iloc[]`, `len()` and `index`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Calling `loc[]` effectively means *creating a subset* (typically based on a relational or logical expression over one or more columns of the dataset). In other words, `loc[]` creates a *slice* of the dataframe, so the type of the result is `<pd.df>`.\n",
    "\n",
    "Note that `loc[]` works as `loc[<selected rows>, <selected columns>]`. The indices `<selected rows>` and `<selected columns>` can be created either directly in `loc[]` or beforehand.\n",
    "\n",
    "If defining the <selected rows> index to be used with `loc[]` subsequently, it is a good practice to define it as a boolean *mask* over a single column, like `<pd.df>['<column>'].isna()`, or as a logical expression in which each chunk is a relational expression over a single column, e.g. `<pd.df>['<column1>'].isna() & <pd.df>['<column2>'] < 23`. The result will be a subset of the original dataframe (i.e., another `<pd.df>`)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Defining the relevant index with a statement like `<pd.df>.loc[<pd.df>['<column>'].isna()].index` is a good starting point when using `iloc[]` subsequently.\n",
    "\n",
    "If using `iloc[]`, don't forget the `.index` chunk in the statement used to create the index (such as `<pd.df>.loc[<pd.df>['<column>'].isna()].index`). Without it, the result is another `<pd.df>`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define i_iloc, the index to be used with iloc[], starting from <i> = <pd.df>['<column>'].isna();\n",
    "# iloc[] can be used conveniently here if the relevant index is already defined with <pd.df>.loc[<i>].index, i.e. <pd.df>.loc[<pd.df>['<column>'].isna()].index;\n",
    "# remember that the second index in iloc[] must be a number too (the relevant column index)\n",
    "\n",
    "# Define i_loc, the index (boolean mask) to be used with loc[], e.g. i_loc = <pd.df>['<column>'].isna()\n",
    "\n",
    "# display(songs.loc[i_loc.index, ['Title', 'Album']])\n",
    "# display(songs.iloc[i_iloc, [0, 2]])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Replace `NaN` values in `Duration` with 'No' (`<pd.df>.loc[<i_loc>, '<column>'] = <new value>`, `<pd.df>.iloc[<i_iloc>, <column index>] = <new value>`)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Make the replacement and display it\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Double-check the missing values now:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Use <pd.df>.Duration.isna().sum(), or <pd.df>.isna().sum()['Duration'] or sb.heatmap(<pd.df>.isna(), cmap='...')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "How many songs from the beginning of The British Invasion are there?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define the beginning of The British Invasion a list comprehension\n",
    "\n",
    "# Display the songs from the early years using a combination of <pd.df>.loc[] and isin()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Grouping and sorting data\n",
    "- `<pd.df>['<column>'].unique()`, `<pd.df>['<column>'].nunique()`\n",
    "- `<pd.df>.<column>.groupby()`, `<pd.df>.groupby('<column>')`, `<pd.df>.groupby('<column>').get_group(<value>)`\n",
    "- `<pd.df>['<column>'].value_counts()`, `<pd.df>['<column>'].value_counts().sort_index()`, `<pd.df>['<column>'].value_counts().sort_index(inplace=True)`\n",
    "- `<pd.df>.sort_values(by='<column name>', ascending=False/True)`\n",
    "- `<pd.df>.groupby('<column>').<another column>.<f()>.sort_values(ascending=False)` (aggregate using function `f()`, e.g. `mean()`)\n",
    "- `<pd.df>.groupby('<column>').<another column>.agg(['<f1 name>', '<f2 name>', ...])` (aggregate using multiple functions, e.g. `mean()`, `count()`,...)\n",
    "\n",
    "If `sort_values()` is used after `agg([<'f1 name>', '<f2 name>', ...])` (`agg(['<f1 name>', '<f2 name>', ...]).sort_values(by='<f name>', ascending=False)`), it must be passed one positional argument (`by='<f name>'`) before the optional `ascending=False`.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "How many unique values for `Year` are there in the dataset (`<pd.df>['<column>'].unique()`, `<pd.df>.<column>.unique()`; `<pd.df>['<column>'].nunique()`, `<pd.df>.<column>.nunique()`)?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Group the songs in the dataset by the year of release (`<pd.df>.groupby('<column>')`). The result can be `songs_by_year`. Display it, show its type, and explore its individual groups and their types (`<pd.df>.groupby('<column>').get_group(<value>)`). "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "How many songs are there in the dataset for each `Year` (`<pd.df>['<column>'].value_counts()`, `<pd.df>['<column>'].value_counts()[<year>]`, `<pd.df>['<column>'].value_counts().sort_index()`)?\n",
    "\n",
    "Note that `value_counts()` returns a `pd.Series` object, with the index equal to `<pd.df>['<column>'].unique()` values."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Sort the songs from the dataset by the year of release (`<pd.df>.sort_values(by='<column name>', ascending=False/True)`).\n",
    "(It is also possible to use `inplace=True` in `sort_values()`, but it will change the order of songs in the dataset from that point on.)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Group the songs in the dataset by the year of release and display `mean` and/or `max` duration of the songs in each year, as well as the number (`count`) of songs in each year (`<pd.df>.groupby('<column>').<another column>.<f()>.sort_values(ascending=False)` (aggregate using function `f()`, e.g. `mean()`), `<pd.df>.groupby('<column>').<another column>.agg(['f1 name>', '<f2 name>', ...])` (aggregate using multiple functions, e.g. `mean()`, `count()`, `max()`,...)).\n",
    "If `sort_values()` is used after `agg([<'f1 name>', '<f2 name>', ...])` (`agg(['<f1 name>', '<f2 name>', ...]).sort_values(by='<f name>', ascending=False)`), it must be passed one positional argument (`by='<f name>'`) before the optional `ascending=False`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# To make all strings in songs.Duration look alike, insert placeholder values of the form 'mm:ss' \n",
    "# for those that are NaN, or that have been previously set to 'No', or the like\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Make sure that now all strings in songs.Duration are of the form 'mm:ss', i.e. they contain ':'\n",
    "# using len(songs.Duration.str.contains(':')) or all(songs.Duration.str.contains(':'))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Convert Duration to int\n",
    "\n",
    "# Define to_sec() function that converts a single string of the form 'mm:ss' to int\n",
    "\n",
    "# Use <pd.df>.<column>.apply(<function>) to convert the entire Duration column to int\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Make the groupings and aggregations\n",
    "\n",
    "# <pd.df>.groupby('<column>').<another column>.<f()>.sort_values(ascending=False)\n",
    "\n",
    "# <pd.df>.groupby('<column>').<another column>.agg(['<f1 name>', '<f2 name>', ...]).sort_values(by='<f name>', ascending=False)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data visualization\n",
    "Plot some scatterplots, line plots, bar graphs, histograms, scatterplots, box plots, violins, heatmaps,...\n",
    "[Example](https://www.analyticsvidhya.com/blog/2021/08/how-to-perform-exploratory-data-analysis-a-guide-for-beginners/)\n",
    "\n",
    "[Matplotlib examples](https://matplotlib.org/stable/gallery/index.html)\n",
    "[Seaborn examples](https://seaborn.pydata.org/examples/index.html) (see also [The Python Graph Gallery](https://www.python-graph-gallery.com/); it has a very neat user interface!)\n",
    "[Plotnine examples](https://plotnine.readthedocs.io/en/stable/api.html) (click on any element for its API and examples)\n",
    "\n",
    "<u>**Note that it is also possible to**</u> <u>**[plot lines, bargraphs,... with Pandas only](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.line.html)**</u> (although in such cases Pandas interacts with Matplotlib under the hood)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Scatterplot"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Read a slightly different dataset.\n",
    "\n",
    "`pd.read_csv()` returns a `pd.DataFrame` object.\n",
    "\n",
    "As for specifying the path of the dataset properly, see [this](https://stackoverflow.com/questions/35384358/how-to-open-my-files-in-data-folder-with-pandas-using-relative-path) (more specifically, **both** [this](https://stackoverflow.com/a/35384414/1899061) and [this](https://stackoverflow.com/a/43600253/1899061))."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Get the songs as a pd.DataFrame object from 'data/stones_analysis.csv', \n",
    "# or from '../data/stones_analysis.csv.csv', or '../../data/stones_analysis.csv.csv', or ...,\n",
    "# depending on where the csv file is located\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Check for missing values (use, e.g., `sb.heatmap(<pd.df>.isna(), cbar=False, cmap='viridis')`)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Scatterplot the relationship between `Duration` and `danceability`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To set the ranges of values on x-axis and y-axis (`Duration`, `danceability`), check the max values or run `describe()`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### 1. Matplotlib version"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Matplotlib scatterplot example](https://matplotlib.org/stable/gallery/shapes_and_collections/scatter.html)\n",
    "\n",
    "Use the following syntax:\n",
    "`ax = plt.axes()`\n",
    "`ax.set(xlim=(<from>, <to>), ylim=(<from>, <to>), xlabel='<xlabel>', ylabel='<ylabel>', title='<title>')`\n",
    "`ax.scatter(<pd.df>['<X>'], <pd.df>['<Y>'], marker='<marker type>', c='<fill color>', edgecolors='<edgecolor>', s=<marker size>)`; \n",
    "the `<pd.df>['<X>']` and `<pd.df>['<Y>']` arguments can be also specified as `<pd.df>.<X>` and `<pd.df>.<Y>` if `<X>` and `<Y>` are single words.\n",
    "The color parameter (`c`) is optional; if present, it should be a scalar or a sequence of length consistent with the lengths of `<X>` and `<Y>` (`(<X>, <Y>)` points). The `marker` parameter is optional as well. Both `c` and `marker` have defaults. For other values of `c` and `marker`, see [this](https://matplotlib.org/stable/gallery/color/named_colors.html#css-colors) and [this](https://matplotlib.org/stable/api/_as_gen/matplotlib.markers.MarkerStyle.html#matplotlib.markers.MarkerStyle.markers), respectively. A good value for `s` is 30-40 for 200-300 markers on the plot.\n",
    "\n",
    "Alternatively:\n",
    "`ax.plot(<pd.df>['<X>'], <pd.df>['<Y>'], marker='<marker type>', color='<color>', linestyle='');`\n",
    "The `linestyle=''` parameter is essential for plotting the dots only - omitting it means that the connecting lines are plotted as well."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### 2. Plotnine version\n",
    "[Plotnine scatterplot example](https://plotnine.readthedocs.io/en/stable/generated/plotnine.geoms.geom_point.html#plotnine.geoms.geom_point)\n",
    "\n",
    "In *Plotnine*, the syntax for setting the ranges on x and y axes is `xlim(<from>, <to>)`, `ylim(<from>, <to>)` (as two separate lines in calling `ggplot()`), or, alternatively, `coord_cartesian(xlim=(<from>, <to>), ylim=(<from>, <to>))` as a single separate line."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If `<x>` and `<y>` values are not columns of a dataframe already (`<X>` and `<Y>`), create a minimal dataframe to support plotting (`<df> = pd.DataFrame({'<X>': <x>, '<Y>': <y>})`)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Use `ggplot` as:\n",
    "\n",
    "`(`\n",
    "&emsp;&emsp;`ggplot(<df>, aes(x='<X>', y='<Y>) +`\n",
    "&emsp;&emsp;`geom_point(color='<color>', fill='<fill color>', shape='<shape>', size=<size>) +`\n",
    "&emsp;&emsp;`coord_cartesian(xlim=(<from>, <to>), ylim=(<from>, <to>)) +`\n",
    "&emsp;&emsp;`theme(figure_size=(10, 7), dpi=60) +`\n",
    "&emsp;&emsp;`labs(x='...', y='...', title='...')`\n",
    "`).draw()`\n",
    "\n",
    "The `color`, `fill` and `shape` parameters have defaults. The other values of these parameters are the same as in Matplotlib (see [this](https://matplotlib.org/stable/gallery/color/named_colors.html) and [this](https://matplotlib.org/stable/api/_as_gen/matplotlib.markers.MarkerStyle.html#matplotlib.markers.MarkerStyle), respectively).\n",
    "\n",
    "In `theme(figure_size=(10, 7), dpi=60)`, the `dpi` parameter is necessary to achieve full control over the plot size (`figure_size` is not enough). It is a good idea to experiment with the actual values for `figure_size`and `dpi`. \n",
    "\n",
    "**Note 1:** `aes(x='<X>', y='<Y>)` shows compiler errors but works anyway; `aes('<X>', '<Y>)` does not show any compiler error. However, `labs(x='...', y='...', title='...')` shows compiler errors regardless of `x=...`, `y=...`, ..., but works only *with* `x=...`, `y=...`. To eliminate these compiler errors, use `xlab('...')`, `ylab('...')` and `ggtitle('...')` as separate lines after calling `ggplot()`. \n",
    "\n",
    "**Note 2:** Once the figure size is changed for plotnine graphs by calling `theme(figure_size=(10, 7), dpi=60)` or similar, the Matplotlib graphs use the new figure size as well and how to control it is a mystery. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### 3. A brief analysis of the plot: What are the shortest/longest songs and their durations?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# display(<pd.df>['column'] <= <value>)                                    # Boolean mask\n",
    "# display(type(<pd.df>['column'] <= <value>))                              # pd.Series\n",
    "# display(<pd.df>[<pd.df>['column'] <= <value>]['column to to display'])   # select one column\n",
    "# display(<pd.df>[<pd.df>['column'] <= <value>]['column 1  to to display', 'column 2 to display',...])   # select multiple columns\n",
    "\n",
    "# Try this also with .loc[], as well as with .iloc[], with an explicitly set index and with .index\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Line plot"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "How many songs from each year are there? (Use the `Year_released` column, rather than `Year_recorded`.)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Use <pd.df>['<column>'].value_counts(), <pd.df>['<column>'].value_counts()[<specific value> in <column>]\n",
    "# In this example, use the Year_released column, rather than Year_recorded\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T21:04:51.638748900Z",
     "start_time": "2023-12-18T21:04:51.584599Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Sort this result by index: `pd.Series.sort_index()` (there is also `pd.DataFrame.sort_index()`)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define val_counts_sorted_by_index\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Preparation for plotting (`counts` on y-axis, `year` on x-axis): get the `np.ndarray` version of `val_counts_sorted_by_index`, as well as of its index.\n",
    "\n",
    "One way of doing it is to use `np.array()` over `val_counts_sorted_by_index.index` and `val_counts_sorted_by_index.values`. However, the same effect is achieved using only `val_counts_sorted_by_index.index` and `val_counts_sorted_by_index.values` (their type is `np.ndarray`)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "And now plot it."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### 1. Matplotlib version\n",
    "[Matplotlib line plot example](https://matplotlib.org/stable/gallery/lines_bars_and_markers/simple_plot.html)\n",
    "\n",
    "`ax = plt.axes()`\n",
    "`ax.set(xlim=(<lower limit>, <upper limit>), ylim=(<lower limit>, <upper limit>), xlabel='...', ylabel='...', title='...')`\n",
    "`ax.ticklabel_format(useOffset=False)`\n",
    "`ax.plot(<x>, <y>, color='...', marker='<marker type>', linewidth=<number>, alpha=<number>)`\n",
    "\n",
    "To prevent numbers displayed in scientific notation (exponential) on axes ticks, make sure to use `ax.ticklabel_format(useOffset=False)`.\n",
    "\n",
    "Do not use `x=<x>, y=<y>` in `ax.plot()`, it generates an error. Use just `<x>, <y>`. For the other parameters, the keywords are necessary.\n",
    "\n",
    "Examples of parameters in `ax.plot()`: `color='steelblue'`, `linewidth=3`, `alpha=0.8` (alpha: transparency (0-1))."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### 2. Plotnine version\n",
    "[Plotnine line plot example](https://plotnine.readthedocs.io/en/stable/generated/plotnine.geoms.geom_line.html#plotnine.geoms.geom_line)\n",
    "[Excellent tutorial on plotnine](https://realpython.com/ggplot-python/)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For some reasons, running the Matplotlib version immediately before running the Plotnine version sometimes resets all values in `year` to 1970 (!!!), so re-creating `year` here might be necessary."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# year = np.array(val_counts_sorted_by_index.index)\n",
    "# display(year)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If `<x>` and `<y>` values are not in a dataframe columns (`<X>` and `<Y>`) already, create a minimal dataframe to support plotting (`<df> = pd.DataFrame({'<X>': <x>, '<Y>': <y>})`)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Use `ggplot` as:\n",
    "\n",
    "`(`\n",
    "&emsp;&emsp;`ggplot(<df>, aes(<x> = '<X>', <y> = '<Y>) +`\n",
    "&emsp;&emsp;`geom_line(color='<color>', size=<size>, alpha=<transparency, 0-1>, linetype='<linetype>') +`\n",
    "&emsp;&emsp;`labs(x='...', y='...')`\n",
    "`).draw()`\n",
    "\n",
    "Examples of parameters in `geom_line()`: `color='steelblue'`, `size=1`, `linetype='solid'`, `alpha=0.8` (alpha: transparency (0-1)).\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### 3. Smoothen the curves\n",
    "Based on [this](https://stackoverflow.com/a/5284038/1899061).\n",
    "`from scipy.interpolate import make_interp_spline, BSpline`\n",
    "\n",
    "`<x> = <definition of x-axis variable>`\n",
    "`<y> = <definition of y-axis variable>`\n",
    "\n",
    "`<x_smooth> = np.linspace(<x>.min(), <x>max(), 300)`&emsp;&emsp;&emsp;&emsp;# 300: the number of points to make between `<x>.min() and <x>.max()`\n",
    "`spl = make_interp_spline(year, counts, k=3)`&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; # type: BSpline\n",
    "`<y_smooth> = spl(<x>_smooth)`\n",
    "\n",
    "`plt.xlim([<lowest value of x to show on the plot>, <highest value of x to show on the plot>])`\n",
    "`plt.ylim([<lowest value of y to show on the plot>, <highest value of x to show on the plot>])`\n",
    "\n",
    "`plt.plot(<x_smooth>, <y_smooth>)`\n",
    "`plt.plot(<x>, <y>)`&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;# optional: show the segmented line on the same plot as well\n",
    "`plt.show()`\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # 300 represents the number of points to make between T.min and T.max\n",
    "# T = np.array([6, 7, 8, 9, 10, 11, 12])\n",
    "# power = np.array([1.53E+03, 5.92E+02, 2.04E+02, 7.24E+01, 2.72E+01, 1.10E+01, 4.70E+00])\n",
    "#\n",
    "# # plt.plot(T,power)\n",
    "# # plt.show()\n",
    "#\n",
    "# xnew = np.linspace(T.min(), T.max(), 300)\n",
    "#\n",
    "# spl = make_interp_spline(T, power, k=3)  # type: BSpline\n",
    "# power_smooth = spl(xnew)\n",
    "#\n",
    "# plt.plot(xnew, power_smooth)\n",
    "# plt.show()\n",
    "\n",
    "# from scipy.interpolate import make_interp_spline, BSpline\n",
    "# \n",
    "# year_smooth = np.linspace(years.min(), years.max(), 300)\n",
    "# spl = make_interp_spline(years, counts, k=3)  # type: BSpline\n",
    "# counts_smooth = spl(year_smooth)\n",
    "# \n",
    "# plt.ticklabel_format(useOffset=False)\n",
    "# \n",
    "# plt.xlim([1961, 2020])\n",
    "# plt.ylim([0, 40])\n",
    "# \n",
    "# plt.xlabel('year')\n",
    "# plt.ylabel('count')\n",
    "# plt.title('Song counts over years')\n",
    "# \n",
    "# plt.plot(year_smooth, counts_smooth)\n",
    "# plt.plot(years, counts)\n",
    "# plt.show()\n",
    "#\n",
    "# # Alternatively\n",
    "# ax = plt.axes()\n",
    "# ax.set(xlim=(years.min(), years.max()), ylim=(0, 70), xlabel='year', ylabel='count', title='Song counts over years')\n",
    "# ax.plot(years, counts, color='steelblue', linewidth=2, marker='o', alpha=0.8)\n",
    "# ax.plot(year_smooth, counts_smooth, color='steelblue', linewidth=3, alpha=0.8);"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### 4. Multiple subplots\n",
    "(shown here after [this](https://jakevdp.github.io/PythonDataScienceHandbook/04.08-multiple-subplots.html))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # From https://jakevdp.github.io/PythonDataScienceHandbook/04.08-multiple-subplots.html\n",
    "# fig = plt.figure()\n",
    "# ax1 = fig.add_axes([0.1, 0.55, 0.8, 0.4],\n",
    "#                    xticklabels=[], ylim=(-1.2, 1.2))\n",
    "# ax2 = fig.add_axes([0.1, 0.1, 0.8, 0.4],\n",
    "#                    ylim=(-1.2, 1.2))\n",
    "# # Meanings of the numbers in [0.1, 0.55, 0.8, 0.4]:\n",
    "# #     0.1 - distance from the left edge of fig (grey area)\n",
    "# #     0.55 - distance between the upper and lower subplots (0.5: they touch each other)\n",
    "# #     0.8 - distance from the right edge of fig (grey area)\n",
    "# #     0.4 - area assigned to the upper/lower subplot (ax1/ax2) along the vertical axes\n",
    "# # Experiment with these numbers to get a better feeling for them\n",
    "\n",
    "# x = np.linspace(0, 10)\n",
    "# ax1.plot(np.sin(x))\n",
    "# ax2.plot(np.cos(x));\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax\n",
    "\n",
    "\n",
    "# fig = plt.figure()\n",
    "# # fig\n",
    "# ax1 = fig.add_axes([0.1, 0.559, 0.8, 0.4],\n",
    "#                    xlim=(1962, 2020), ylim=(0, 35),\n",
    "#                    xlabel='year', ylabel='counts',\n",
    "#                    title='Number of songs recorded over the years')\n",
    "# ax2 = fig.add_axes([0.1, 0.105, 0.8, 0.35],\n",
    "#                    xlim=(1962, 2020), ylim=(0, 35),\n",
    "#                    xlabel='year', ylabel='counts',\n",
    "#                    title='Number of songs recorded over the years')\n",
    "# # display(type(ax1))\n",
    "# ax1.ticklabel_format(useOffset=False)\n",
    "# ax2.ticklabel_format(useOffset=False)\n",
    "# \n",
    "# ax1.plot(years, counts, color='steelblue', linewidth=1.5, alpha=0.8)    # alpha: transparency (0-1)\n",
    "# ax2.plot(years, counts, color='purple', linewidth=1.5, alpha=0.8);      # alpha: transparency (0-1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Histogram"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Use Pandas to extract song lengths as a `pd.Series` object (`<pd.Series object> = <pd.df>['<column>']`)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Get the song lengths as a pd.Series object\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T23:11:19.188761500Z",
     "start_time": "2023-12-15T23:11:19.186558400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Convert the song lengths into a NumPy array (using <song lengths>.to_numpy() or np.array(<song lengths>))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T23:11:30.661616700Z",
     "start_time": "2023-12-15T23:11:30.568358700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### 1. Matplotlib version\n",
    "[Matplotlib histogram example](https://matplotlib.org/stable/gallery/statistics/hist.html)\n",
    "\n",
    "Plot the histogram of the song lengths using Matplotlib.\n",
    "\n",
    "Minimal version: `plt.hist(<x>, bins=<number of bins>);` or `sb.histplot(<x>, bins=<number of bins>)`.\n",
    "\n",
    "Alternatively:\n",
    "`ax = plt.axes()`\n",
    "`ax.set(xlabel='...', ylabel='...', title='...')`\n",
    "`ax.hist(<x>, bins=<number of bins>)`\n",
    "\n",
    "As for the plot styles, there are a lot of [available styles](https://www.dunderdata.com/blog/view-all-available-matplotlib-styles) that can be also shown in code using `plt.style.available`. See also [this](https://www.analyticsvidhya.com/blog/2021/08/exploring-matplotlib-stylesheets-for-data-visualization/).\n",
    "\n",
    "Alternatively, plot style can be set using `sb.set_theme(palette='...')` (or just `sb.set()`, but that function might get deprecated and removed from *Seaborn* in the future). See [`sb.set_theme()` documentation](https://seaborn.pydata.org/generated/seaborn.set_theme.html) for the function's parameters and defaults. For `palette='...'` use any of the palettes shown with `plt.style.available`, or any of [these](https://matplotlib.org/stable/users/explain/colors/colormaps.html#qualitative), or..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Set plot style using sb.set_theme(palette='Pastel2')\n",
    "\n",
    "# Plot the histogram - x: song time in [sec]; y: number of songs; 40 bins\n",
    "\n",
    "# Minimal version\n",
    "\n",
    "# A more detailed version\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T23:12:09.193727900Z",
     "start_time": "2023-12-15T23:12:09.057852800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### 2. Plotnine version\n",
    "[Plotnine histogram example](https://plotnine.readthedocs.io/en/stable/generated/plotnine.geoms.geom_histogram.html#plotnine.geoms.geom_histogram)\n",
    "\n",
    "Plot the histogram of the song lengths using *Plotnine*.\n",
    "\n",
    "A minimal, but effective version:\n",
    "`plot = ggplot(songs, aes(x='<x>'))`\n",
    "`plot + geom_histogram(bins=40)`\n",
    "\n",
    "A more detailed version:\n",
    "`(`\n",
    "&emsp;&emsp;`ggplot(songs, aes(x='<x>')) +`\n",
    "&emsp;&emsp;`geom_histogram(bins=40, color='<color>', fill='<fill>', size='<outline thickness>', alpha=<transparency, 0-1>) +`\n",
    "&emsp;&emsp;`labs(x='<x>', y='count', title='<title>')`\n",
    "`).draw()`\n",
    "\n",
    "[Excellent tutorial on plotnine](https://realpython.com/ggplot-python/)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "# Minimal version\n",
    "# plot = ggplot(songs, aes(x='Duration'))\n",
    "# plot + geom_histogram(bins=40)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To avoid the annoying text output like `<ggplot: (177159008578)>` under the plot, use the following syntax:\n",
    "\n",
    "`(`\n",
    "&emsp;&emsp;`ggplot(songs, aes(x='<x>')) +`\n",
    "&emsp;&emsp;`geom_histogram(bins=40, color='<color>', fill='<fill>', size='<outline thickness>', alpha=<transparency, 0-1>) +`\n",
    "&emsp;&emsp;`labs(x='<x>', y='count', title='<title>')`\n",
    "`).draw()`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T23:12:33.394426500Z",
     "start_time": "2023-12-15T23:12:33.278732Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Bar graph"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "How many Rolling Stones songs have reached Billboard Top 50?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Read the dataset (`'../data/stones_analysis.csv'`) and make some minor transformations.\n",
    "\n",
    "`pd.read_csv()` returns a `pd.DataFrame` object.\n",
    "\n",
    "As for specifying the path of the dataset properly, see [this](https://stackoverflow.com/questions/35384358/how-to-open-my-files-in-data-folder-with-pandas-using-relative-path) (more specifically, **both** [this](https://stackoverflow.com/a/35384414/1899061) and [this](https://stackoverflow.com/a/43600253/1899061))."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Get the songs as a pd.DataFrame object from 'data/The Rolling Stones songs dataset, v1.csv', or from\n",
    "# '../data/stones_analysis.csv', or '../../data/stones_analysis.csv', or ..., \n",
    "# depending on where the csv file is located\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T23:12:54.392367600Z",
     "start_time": "2023-12-15T23:12:54.290241400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Add another column, `Top100`: a song has reached the US Top 100 chart (`Yes`), or it hasn't (`No`)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T23:12:59.470236100Z",
     "start_time": "2023-12-15T23:12:59.385461Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create the index of the songs that HAVE reached the US Top 100 chart : `i = songs.loc[songs['US'] != 'No'].index` or `i = np.array(songs.loc[songs['US'] != 'No'].index)`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T23:13:15.208730100Z",
     "start_time": "2023-12-15T23:13:15.076023200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Change the values of `Top100` corresponding to the created index to `Yes`. **Make sure to work on a <u>copy</u> of the `Top100` columns (e.g., `top100 = songs.Top100.copy()`), to avoid the caveat of working on the dataframe directly.**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T23:13:25.221474500Z",
     "start_time": "2023-12-15T23:13:25.137696400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Check if the newly added `Top100` column is now OK. Try this using the index created in the previous step, as well as using `i = songs.loc[songs['US'] != 'No'].index` directly."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T23:13:34.496199500Z",
     "start_time": "2023-12-15T23:13:34.405448400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<u>Save this version as a new *.csv* file, for use in the subsequent examples.</u> (`<pd.df>.to_csv('<path>')`)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T23:13:46.212766200Z",
     "start_time": "2023-12-15T23:13:46.114028300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### Preparing the data for plotting the bar graph"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Group the data - group the songs by the year of release."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T23:13:59.253383200Z",
     "start_time": "2023-12-15T23:13:59.147666900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Use `get_group(<year>)` to get all songs for a selected year and `value_counts()` over the resulting group's `Top100` column (showing the `Yes` and `No` subgroups). This is a precursor to creating the data for the y-axis of the bar graph."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T23:14:36.500861Z",
     "start_time": "2023-12-15T23:14:36.397136600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Build the data to plot by extracting relevant items from each group."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For x-axis, use `unique()` over the `Year_released` column and then `np.sort()` the results."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T23:14:49.890438800Z",
     "start_time": "2023-12-15T23:14:49.783722400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For y-axis, create the lists of the numbers of the songs that have reached the US Top 100 (`in_top100`) and of those that haven't (`not_in_top100`).\n",
    "(Start from two empty lists. Loop over the sorted list of years created in the previous step, `get_group()` for each year and append the `value_counts()['Yes']` of the `Top100` column of the current year (`y['Top100']`) to `in_top50` if any of `y['Top100']` has the value `Yes`, otherwise append 0. Do the similar thing for `not_in_top100`. Display both lists in the end to double-check the result.)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T23:15:02.907731Z",
     "start_time": "2023-12-15T23:15:02.824580200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "And now plot the bar graph. Based on the second example from [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.bar.html) (using `<pd.df>.plot.bar()`, not Matplotlib or Seaborn).\n",
    "For a complete list of parameters used in `**kwargs`, see [this](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.html).\n",
    "For a list of named colors (Matplotlib named colors), see [here](https://matplotlib.org/stable/gallery/color/named_colors.html#css-colors)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First create an auxiliary dataframe to use for plotting. Use `in_top50` and `not_in_top50` as the columns, <u>and the sorted list of years created above as the index of the dataframe</u>."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# # The role-model example from https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.bar.html\n",
    "# speed = [0.1, 17.5, 40, 48, 52, 69, 88]\n",
    "# lifespan = [2, 8, 70, 1.5, 25, 12, 28]\n",
    "# index = ['snail', 'pig', 'elephant', 'rabbit', 'giraffe', 'coyote', 'horse']\n",
    "# df = pd.DataFrame({'speed': speed, 'lifespan': lifespan}, index=index)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T23:15:15.908801Z",
     "start_time": "2023-12-15T23:15:15.795173200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Pandas bargraph example](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.bar.html)\n",
    "\n",
    "Use `ax = <pd.df>.plot.bar()` to plot the bargraph.\n",
    "\n",
    "Relevant parameters:\n",
    "- `rot=<rotation angle [degrees]>` for the x-axis labels\n",
    "- `ylim=(<from>, <to>)`\n",
    "- `color={'In Top 50': 'limegreen', 'Not in Top 50': 'navajowhite'}` (for a list of Matplotlib named colors, see [here](https://matplotlib.org/stable/gallery/color/named_colors.html#css-colors))\n",
    "- `edgecolor='<color of bin lines>'`\n",
    "- `title='<title>'`\n",
    "- `xlabel='<xlabel>'`\n",
    "- `ylabel='<ylabel>'`\n",
    "- `fontsize=<fontsize>` (for all text; suitable fontsizes are 10, 12,...)\n",
    "- `stacked=True` (the bins for the same x-axis value stacked on top of one another)\n",
    "\n",
    "The returned value (`ax`) is usually unnecessary and can be omitted."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T23:15:29.035779900Z",
     "start_time": "2023-12-15T23:15:28.933052600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Box plot\n",
    "[Seaborn boxplot example](https://seaborn.pydata.org/generated/seaborn.boxplot.html) (used here as the role model)\n",
    "\n",
    "For Seaborn color palette names see [this](https://seaborn.pydata.org/generated/seaborn.color_palette.html#seaborn.color_palette) or [this](https://10xsoft.org/courses/data-analysis/mastering-data-visualization-with-python/section-4-data-visualization-using-seaborn/colour-palettes-seaborn/). To list the names of some ('quantitative') Seaborn color palettes, use `sb.palettes.SEABORN_PALETTES.keys()` (see [this](https://10xsoft.org/courses/data-analysis/mastering-data-visualization-with-python/section-4-data-visualization-using-seaborn/colour-palettes-seaborn/) and [this](https://www.codecademy.com/article/seaborn-design-ii) for additional named palettes)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Read the dataset (`'data/stones_analysis_top100.csv'`).\n",
    "\n",
    "`pd.read_csv()` returns a `pd.DataFrame` object.\n",
    "\n",
    "As for specifying the path of the dataset properly, see [this](https://stackoverflow.com/questions/35384358/how-to-open-my-files-in-data-folder-with-pandas-using-relative-path) (more specifically, **both** [this](https://stackoverflow.com/a/35384414/1899061) and [this](https://stackoverflow.com/a/43600253/1899061))."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Get the songs as a pd.DataFrame object from 'data/stones_analysis_top100.csv', or from\n",
    "# '../data/stones_analysis_top100.csv', or '../../data/stones_analysis_top100.csv.csv', or ..., depending on where the csv file is located\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T23:15:41.314406200Z",
     "start_time": "2023-12-15T23:15:41.174333200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Use `sb.boxplot()` to plot some boxplots.\n",
    "\n",
    "For a single-column boxplot, relevant parameters are `y=<pd.df>['column']` (for 'vertical' boxplot) or `x=<pd.df>['column']` (for 'horizontal' boxplot), and `palette='palette'` (e.g., 'Set3', 'pastel', ...; see the links above for other named color palettes).\n",
    "\n",
    "For a multiple-column boxplot, relevant parameters are `data=<pd.df>[['column1', 'column2',...]]`, `orient='v'` (for 'vertical' boxplot) and `palette='palette'`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# display(sb.palettes.SEABORN_PALETTES.keys())\n",
    "\n",
    "# For a single column (e.g., Duration)\n",
    "# # sb.boxplot(x=songs.Duration, palette='Set1');\n",
    "# sb.boxplot(y=songs.Duration, palette='Set1');\n",
    "\n",
    "# For multiple columns (e.g., energy and acousticness)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T23:15:50.296475Z",
     "start_time": "2023-12-15T23:15:50.206691300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Violin plot\n",
    "[Seaborn violin plot example](https://seaborn.pydata.org/generated/seaborn.violinplot.html)\n",
    "\n",
    "Combines box plot and density plot. Based on [this](https://stackoverflow.com/questions/46134113/seaborn-violin-plot-from-pandas-dataframe-each-column-its-own-separate-violin-p) and [this](https://seaborn.pydata.org/generated/seaborn.violinplot.html)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Read the dataset (`'data/stones_analysis_top100.csv'`).\n",
    "\n",
    "`pd.read_csv()` returns a `pd.DataFrame` object.\n",
    "\n",
    "As for specifying the path of the dataset properly, see [this](https://stackoverflow.com/questions/35384358/how-to-open-my-files-in-data-folder-with-pandas-using-relative-path) (more specifically, **both** [this](https://stackoverflow.com/a/35384414/1899061) and [this](https://stackoverflow.com/a/43600253/1899061))."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Get the songs as a pd.DataFrame object from 'data/stones_analysis_top100.csv', or from\n",
    "# '../data/stones_analysis_top100.csv', or '../../data/stones_analysis_top100.csv.csv', or ..., depending on where the csv file is located\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T23:16:01.828301500Z",
     "start_time": "2023-12-15T23:16:01.741530500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Use `sb.violinplot()` like: `sb.violinplot(x=<pd.df>.loc[<selected indices for <column 1>, '<column 1>'], y=<pd.df>['<column 2>'], palette='<palette>')`.\n",
    "\n",
    "For example, if the violin plot should represent density/boxplot diagram of song `Duration` in certain `Year`s (`Year_released`s), then `<column 1>` is `Year` and `<column 2>` is `Duration`. Good values for `'<palette>'` are, e.g., 'Set3', 'pastel',...).\n",
    "\n",
    "Try setting the index of selected observations both implicitly (directly in the `x` parameter) and explicitly (before the call to `sb.violinplot()`) and then using `x=<pd.df>.loc[<index>, '<column for x-axis>']`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T23:16:12.856936300Z",
     "start_time": "2023-12-15T23:16:12.758053200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Heat map\n",
    "[Seaborn heat map example](https://seaborn.pydata.org/generated/seaborn.heatmap.html) (used here as the role model)\n",
    "\n",
    "To create a heatmap, create the corresponding pivot table first. [An intuitive visual explanation of pivot tables](https://support.microsoft.com/en-us/office/overview-of-pivottables-and-pivotcharts-527c8fa3-02c0-445a-a2db-7794676bce96#:~:text=A%20PivotTable%20is%20an%20interactive,unanticipated%20questions%20about%20your%20data.).\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Read the dataset (`'data/stones_analysis_top100.csv'`). This dataset already has been saved when plotting the bar graph above, so it already has the `Top100` column.\n",
    "\n",
    "`pd.read_csv()` returns a `pd.DataFrame` object.\n",
    "\n",
    "As for specifying the path of the dataset properly, see [this](https://stackoverflow.com/questions/35384358/how-to-open-my-files-in-data-folder-with-pandas-using-relative-path) (more specifically, **both** [this](https://stackoverflow.com/a/35384414/1899061) and [this](https://stackoverflow.com/a/43600253/1899061))."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Get the songs as a pd.DataFrame object from 'data/stones_analysis_top100.csv', or from\n",
    "# '../data/stones_analysis_top100.csv', or '../../data/stones_analysis_top100.csv', \n",
    "# or ..., depending on where the csv file is located\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T23:16:25.335319100Z",
     "start_time": "2023-12-15T23:16:25.246557200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Categorize songs according to their *valence*.\n",
    "Insert a new column, e.g. `valence_category` and set it to the default value `Medium`. Then split the range of `valence` to five subranges, `very-Low` to `very_high` (find the `max()` of `valence` first). Each such a subrange is actually an index of selected songs, based on the value of `valence` (e.g., `very_low = songs['valence'] < 10`). Then use `<pd.df>.loc[<index of selected observations>, <relevant column>]` to change the default value `Medium` where appropriate (e.g., `songs.loc[very_low, 'valence_category'] = 'Very Low'`)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T23:16:32.649650600Z",
     "start_time": "2023-12-15T23:16:32.581829900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T23:16:39.954149800Z",
     "start_time": "2023-12-15T23:16:39.854414100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Rearrange the categories of `valence_category` to make the output natural.\n",
    "Use `<pd.df>['<column>'] = pd.Categorical(<pd.df>[<column>], categories=['<cat1>, <cat2>, ...'], ordered=True)`. In this example, order categories from `Very High` to `Very Low`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T23:16:52.979608Z",
     "start_time": "2023-12-15T23:16:52.902263100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create a suitable pivot table. Use `<pivot table> = <pd.df>.pivot_table(values='<column with values to show on the heatmap>', index='<categorical index>', columns='<column>')`\n",
    "- `values`: e.g. `loudness`\n",
    "- `index`: to be shown on y-axis, e.g. `valence_category`\n",
    "- `columns`: to be shown on x-axis, e.g. `Year_released`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T23:17:11.944827500Z",
     "start_time": "2023-12-15T23:17:11.870002400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot the corresponding heatmap. Based on [this](https://pythonbasics.org/seaborn-heatmap/), [this](https://seaborn.pydata.org/generated/seaborn.heatmap.html), and [this](https://stackoverflow.com/a/29648332/1899061).\n",
    "\n",
    "It is often a good idea to change the default figure size first, using `sb.set_theme(rc={'figure.figsize': (<x_size>, <y_size>)})`, to avoid cluttering on the heatmap. Here `rc` stands for 'run command' - essentially, configurations which will execute when running the code. Experiment with `(<x_size>, <y_size>)`. The values that have worked well in this example: (15.7, 5.27).\n",
    "\n",
    "Then use `sb.heatmap(data=<pivot table>, annot=True, fmt='<format string>', cmap='<color map>');`\n",
    "- `data=<pivot table>`: the pivot table created in the previous step\n",
    "- `annot=True`: annotate heatmap cells with values\n",
    "- `fmt='<format_string>'`: for example, use `'.0f'` to show int values in annotations, not scientific notation (`'g'` for using mixed int and float annotations)\n",
    "- `cmap='<color map>'`: color map (see [this](https://10xsoft.org/courses/data-analysis/mastering-data-visualization-with-python/section-4-data-visualization-using-seaborn/colour-palettes-seaborn/)); a good one is `viridis`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T23:17:33.108264200Z",
     "start_time": "2023-12-15T23:17:33.029448800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### A fancier example\n",
    "Average duration of songs over the years, represented as circles with sizes proportional to the numbers of songs."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# songs = pd.read_csv('../data/stones_analysis.csv')\n",
    "# songs_by_year = songs.groupby('Year_released')\n",
    "# years = np.sort(songs.Year_released.unique())\n",
    "# years\n",
    "# \n",
    "# avg_duration = []\n",
    "# for year in years:\n",
    "#     avg_duration.append(np.mean(songs_by_year.get_group(year)['Duration']))\n",
    "# avg_duration = np.array(avg_duration)\n",
    "# \n",
    "# rng = np.random.RandomState(370)\n",
    "# \n",
    "# colors = rng.choice(100, size=len(years), replace=False)                    # random sample, no duplicates\n",
    "# # display(colors)\n",
    "# \n",
    "# sizes = []\n",
    "# for year in years:\n",
    "#     sizes.append(len(songs_by_year.get_group(year)) * 100)                  # sizes proportional to the numbers of songs\n",
    "# \n",
    "# plt.title('Song duration over the years', fontdict={'size': 20})\n",
    "# plt.xlabel('Year')\n",
    "# plt.ylabel('Duration')\n",
    "# plt.xlim(1963, 2020)\n",
    "# plt.ticklabel_format(useOffset=False)\n",
    "# plt.scatter(years, avg_duration,\n",
    "#             c=colors, s=sizes, alpha=0.3,                                   # alpha: the level of transparency\n",
    "#             cmap='Set1')                                                    # cmap: a pre-defined color map\n",
    "# plt.colorbar();                                                             # show color scale\n",
    "# \n",
    "# # # Alternatively, but without showing the colorbar\n",
    "# # ax = plt.axes()\n",
    "# # ax.set(xlabel='Year', ylabel='Duration', xlim=(1963, 2020),\n",
    "# #        title='Song duration over the years')\n",
    "# # plt.ticklabel_format(useOffset=False)\n",
    "# # ax.scatter(years, avg_duration,\n",
    "# #            c=colors, s=sizes, alpha=0.3,                                    # alpha: the level of transparency\n",
    "# #            cmap='Set1');                                                    # cmap: a pre-defined color map"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-15T23:17:47.652076800Z",
     "start_time": "2023-12-15T23:17:47.600185100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking - Boolean arrays as masks"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "A simple example.\n",
    "Create a small `pd.Series` object (e.g., `a`) and a boolean mask as a list of the same length (e.g., `mask`) and show the effect of running `a[mask]`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "An example from the `'../data/The Rolling Stones songs dataset, v2.csv'` dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Read the dataset.\n",
    "\n",
    "`pd.read_csv()` returns a `pd.DataFrame` object.\n",
    "\n",
    "As for specifying the path of the dataset properly, see [this](https://stackoverflow.com/questions/35384358/how-to-open-my-files-in-data-folder-with-pandas-using-relative-path) (more specifically, **both** [this](https://stackoverflow.com/a/35384414/1899061) and [this](https://stackoverflow.com/a/43600253/1899061))."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Get the songs as a pd.DataFrame object from 'data/The Rolling Stones songs dataset, v1.csv', or from\n",
    "# '../data/The Rolling Stones songs dataset, v1.csv', or '../../data/The Rolling Stones songs dataset, v1.csv', \n",
    "# or ..., depending on where the csv file is located\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Extract song release years into a NumPy array (use the `values` attribute of the `Year` column)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Extract songs released after 1968.\n",
    "Create a mask (a Boolean array of the same length as `Year`), `True` if the year is greater than 1968, and show a slice of it. It is a simple relational expression, no need for `.loc[]`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Get the titles of the first 10 songs released after 1968.\n",
    "Use indexing with the mask created in the previous step."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get the titles of the first 10 songs such that years > 1968\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Get the titles of the last 10 songs such that `years > 1968` and `times < 120`.\n",
    "Create two simple masks, one for `Year` and another one for `Duration`, and use `&` in indexing the relevant observations in the dataframe. Remember to use the `values` attribute of both columns to convert the values to NumPy arrays."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get the titles of the last 10 songs such that years > 1968 and times < 120\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Get the titles of all songs released 1966 or 1967, as well as the mean value of their lengths.\n",
    "Create an appropriate mask for years, and use `np.mean()` to show the mean value of the lengths of the songs extracted using the mask.\n",
    "\n",
    "**IMPORTANT:** Element-wise logical operators to compare `pd.Series` objects are `&` and `|`, not `and` and `or`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fancy indexing\n",
    "Fancy indexing is like simple indexing, but arrays of indices are passed in place of single scalars."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an array of 10 random integers (using `np.random.seed(<seed>)`, `<array> = np.random.randint(10, size=10)`) and a list of a couple of indices to select the relevant values from the array. Try also changing the values at these indices only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create an `np.array` of `int` values and demonstrate that `np.sort(<np.array>)` does not change the array, whereas the `<np.array>.sort()` does (inplace sorting)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `np.argsort()` function returns the *indices* that would sort an array."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "What are the longest and the shortest Rolling Stones songs?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Read the dataset, `'../data/The Rolling Stones songs dataset, v1.csv'`.\n",
    "\n",
    "`pd.read_csv()` returns a `pd.DataFrame` object.\n",
    "\n",
    "As for specifying the path of the dataset properly, see [this](https://stackoverflow.com/questions/35384358/how-to-open-my-files-in-data-folder-with-pandas-using-relative-path) (more specifically, **both** [this](https://stackoverflow.com/a/35384414/1899061) and [this](https://stackoverflow.com/a/43600253/1899061))."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Get the songs as a pd.DataFrame object from 'data/The Rolling Stones songs dataset, v1.csv', or from\n",
    "# '../data/The Rolling Stones songs dataset, v1.csv', or '../../data/The Rolling Stones songs dataset, v1.csv', or ..., depending on where the csv file is located\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Extract `times` - song durations - from the `values` attribute of the `Duration` column and pass it to `np.argsort()` to get the index that sorts the song times in the ascending order. To sort in descending order, use `(-<np.array>).argsort()` or `<index> = np.argsort(-<np.array>)` (see [this](https://stackoverflow.com/questions/16486252/is-it-possible-to-use-argsort-in-descending-order)).\n",
    "Use the index created that way to print the titles and the durations of, e.g., ten longest songs and ten shortest songs. It boils down to fancy indexing the `Title` and `Duration` columns with the index created that way."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
