{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory data analysis\n",
    "Introduction to exploratory data analysis (EDA)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA is an approach to analyzing datasets to summarize their main characteristics, often with visual methods. EDA is used for seeing what the data can tell us before the modeling task [(source 1)](https://chartio.com/learn/data-analytics/what-is-exploratory-data-analysis/). It is used to explore the data, find different patterns, relations, and anomalies in the data using some statistical graphs and other visualization techniques, and possibly formulate hypotheses that could lead to new data collection and experiments [(source 2)](https://www.analyticsvidhya.com/blog/2021/08/how-to-perform-exploratory-data-analysis-a-guide-for-beginners/). More specifically, EDA enables analysts to:\n",
    "1. get maximum insights from a data set\n",
    "2. uncover underlying structure\n",
    "3. extract important variables from the dataset\n",
    "4. detect outliers and anomalies (if any)\n",
    "5. test underlying assumptions\n",
    "6. determine the optimal factor settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA steps and tools\n",
    "Practical steps in conducting EDA and frequently used EDA tools.\n",
    "Based on *pandas2020-main.Sales_Analysis_Pandas_P3_tutorial.ipynb* and *pandas2020-main.TED_Talks_Pandas_P3_tutorial.ipynb*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on [this](https://stackoverflow.com/a/22149930/1899061), in all computations, `axis=...` refers to the axis **along which** the computation is done. By default, `axis=0`. This is consistent with the `numpy.mean` usage when axis is specified explicitly (in `numpy.mean`, `axis==None` by default, which computes the mean value over the flattened array), in which `axis=0` along the rows (namely, index in pandas), and `axis=1` along the columns.\n",
    "Note also that that `axis=0` indicates aggregating along rows and `axis=1` indicates aggregating along columns. This is consistent with how we index into a dataframe. In `df.iloc[<row>, <column>]`, `<row>` is in index position 0 and `<column>` is in index position 1. For added clarity, one may choose to specify `axis='index'` (instead of `axis=0`) or `axis='columns'` (instead of `axis=1`).\n",
    "**But**, `axis=0` means each row as a bulk - we manipulate a `pd.DataFrame` inter-row, instead of within-row. Likewise, 1 means each column as a bulk, i.e. we manipulate a `pd.DataFrame` inter-column instead of within-column. For example, `<pd.df>.drop(\"A\", axis=1)` will drop a whole column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the dataset\n",
    "- `pd.read_csv()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial examination and adaptations\n",
    "- `<pd.df>.shape`, `<pd.df>.head()`, `<pd.df>.tail()`, `<pd.df>.sample()`, `<pd.df>.dtypes`, `<pd.df>.info()`, `<pd.df>.describe()`\n",
    "- `<pd.df>.loc[...]`, `<pd.df>.iloc[...]` - examine individual cells, columns, rows\n",
    "    - `loc` works with conditions and column names, `iloc` with numerical indices\n",
    "    - in both `loc` and `iloc`, multiple columns can be specified as a list of column names, and `:` in each index position means 'all'\n",
    "    - in `iloc`, both index positions can be specified as lists of numeric values\n",
    "- `<pd.df>.columns`, `<pd.df>.columns.values`, `<pd.df>.columns.values.tolist()` (or `<pd.df>.columns.values.to_list()`), `<pd.df>.values`\n",
    "- `<pd.df>.rename({'<column_1 old name>':'<column_1 new name>', '<column_2 old name>':'<column_2 new name>', ...}, axis='columns')`, `<pd.df>.columns = ['<column_1 name>', '<column_2 name>', ...]` (change the names of all columns in <pd.df>)\n",
    "- `ast.literal_eval()` (using Python's *ast* module to transform a string into a literal value, a list, a tuple or any other container object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values and value counts\n",
    "- `sb.heatmap()`, e.g. `sb.heatmap(<pd.df>.isna(),cbar=False,cmap='viridis')` ([example](https://www.analyticsvidhya.com/blog/2021/08/how-to-perform-exploratory-data-analysis-a-guide-for-beginners/))\n",
    "- `<pd.df>.isna()` (`<pd.df>.isnull()`), `<pd.df>.isna().sum()` (`<pd.df>.isnull().sum`) ([example](https://www.analyticsvidhya.com/blog/2021/08/how-to-perform-exploratory-data-analysis-a-guide-for-beginners/))\n",
    "- `<pd.df>['<column>'].value_counts()` (shows only the rows without NAs (default: dropna=True), check shape)\n",
    "- `<pd.df>['<column>'].value_counts(normalize=True)` (show proportions, rather than frequencies)\n",
    "- `<pd.Series>.dropna(how='all'/'any', inplace=True)` (return a new `<pd.Series>` object with missing values removed)\n",
    "\n",
    "The `cmap` parameter of `sb.heatmap()` denotes a [Matplotlib colormap](https://matplotlib.org/stable/tutorials/colors/colormaps.html#classes-of-colormaps) (`viridis`, `cividis`, `tab20`, `winter`, `BuPu_r`, `ocean`,...)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining individual data items, rows and columns\n",
    "- `<pd.df>.sample()`\n",
    "- Simple indexing and fancy indexing: `<pd.df>.iloc[]`, `<pd.df>.loc[]`\n",
    "- `<pd.df>.index`, `<pd.df>.index[<from>:<to>]`, `<pd.df>.reset_index(drop=True, inplace=True)`\n",
    "- Indexing using list of values: `<pd.df>.loc[<pd.df>.<column>.isin(<list of values>)]` (select those observations where the value of `<column>` is in the `<list of values>`)\n",
    "- Indexing in data stats: `<pd.df>.describe().loc['50%', '<column_name>']` (select the median of `<column_name>` from the `<pd.df>` stats computed by `describe()`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping and sorting data\n",
    "- `<pd.df>['<column>'].unique()`, `<pd.df>['<column>'].nunique()`\n",
    "- `<pd.df>['<column>'].groupby()`, `<pd.df>['<column>'].groupby().get_group()`\n",
    "- `<pd.df>['<column>'].value_counts()`, `<pd.df>['<column>'].value_counts().sort_index()`, `<pd.df>['<column>'].value_counts().sort_index(inplace=True)`\n",
    "- `<pd.df>.sort_values(by='<column name>', ascending=False/True)`\n",
    "- `<pd.df>.groupby('<column>').<another column>.<f()>.sort_values(ascending=False)` (aggregate using function `f()`, e.g. `mean()`)\n",
    "- `<pd.df>.groupby('<column>').<another column>.agg(['<f1 name>', '<f2 name>', ...])` (aggregate using multiple functions, e.g. `mean()`, `count()`,...)\n",
    "\n",
    "If `sort_values()` is used after `agg(['f1 name>', '<f2 name>', ...])` (`agg(['<f1 name>', '<f2 name>', ...]).sort_values(by='<f name>', ascending=False)`), it must be passed one positional argument (`by='<f name>'`) before the optional `ascending=False`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data transformations\n",
    "- `<pd.df>.describe()`\n",
    "- `pd.to_numeric(<pd.DataFrame object>['<column name>'], errors='coerce')`, `pd.DataFrame.to_numpy()`, `pd.Series.to_numpy()`, `pd.to_datetime()`, ...\n",
    "- `<pd.df>.<column>.apply(<f_name>)` (apply the <f_name> function to all elements of each element of the `<column>`; for example, each element of the `<column>` can be a list of other elements)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring correlations\n",
    "Explore correlations between the (numerical) columns.\n",
    "- `sb.heatmap()`\n",
    "- [Example](https://www.analyticsvidhya.com/blog/2021/08/how-to-perform-exploratory-data-analysis-a-guide-for-beginners/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data visualization\n",
    "Plot some bargraphs, scatterplots, boxplots,...\n",
    "- [Example](https://www.analyticsvidhya.com/blog/2021/08/how-to-perform-exploratory-data-analysis-a-guide-for-beginners/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other\n",
    "[Other interesting ideas and different ways of using the things from above](https://realpython.com/pandas-python-explore-dataset/#exploring-your-dataset) (see the rest from [that article](https://realpython.com/pandas-python-explore-dataset/) as well)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and configure packages\n",
    "The `%run` magic might not work well in DataSpell, thus the following `import` statements are copied here from *import_packages.ipynb*:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%run \"../notebooks/import_packages.ipynb\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# # %load_ext autoreload\n",
    "# # %autoreload 2\n",
    "# \n",
    "# %matplotlib inline\n",
    "# \n",
    "# # %config IPCompleter.greedy=True\n",
    "# \n",
    "# import numpy as np\n",
    "# import matplotlib as mpl\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.style.use('classic')\n",
    "# import pandas as pd\n",
    "# import seaborn as sb\n",
    "# \n",
    "# from plotnine import ggplot, aes, labs, geom_point, geom_line, geom_histogram, theme_xkcd, coord_cartesian, xlim, ylim, xlab, ylab, ggtitle, theme"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing The British Invasion datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Available datasets\n",
    "The British Invasion datasets, located in the *data* folder:\n",
    "* *brit.csv* - complete raw dataset (including data from Spotify, Wikipedia, AllMusic, etc.)\n",
    "* *brit_col_renamed.csv* - same as *brit.csv*, but with column names modified for the sake of consistency\n",
    "* *brit_performers_stripped.csv* - same as *brit_col_renamed.csv*, but with performer names stripped for `\\n` etc.\n",
    "* *brit_titles_stripped* - same as *brit_performers_stripped.csv*, but with song titles rstripped\n",
    "* *attrs.csv* - incomplete raw dataset (some of the attributes from [a Kaggle dataset](https://www.kaggle.com/datasets/saurabhshahane/music-dataset-1950-to-2019))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the *csv* file containing one of the available datasets describing The British Invasion songs\n",
    "`pd.read_csv()` returns a `pd.DataFrame` object.\n",
    "\n",
    "As for specifying the path of the dataset properly, see [this](https://stackoverflow.com/questions/35384358/how-to-open-my-files-in-data-folder-with-pandas-using-relative-path) (more specifically, **both** [this](https://stackoverflow.com/a/35384414/1899061) and [this](https://stackoverflow.com/a/43600253/1899061))."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Get the songs as a pd.DataFrame object from 'data/brit.csv', \n",
    "# or from '../data/brit.csv', \n",
    "# or '../../data/brit.csv', \n",
    "# or ..., \n",
    "# depending on where the csv file is located\n",
    "\n",
    "songs = pd.read_csv('../data/brit.csv')\n",
    "songs\n",
    "\n",
    "# If an int column contains NaN values, read_csv() sets all values to float values, because NaN are internally\n",
    "# represented as float values. To read the int columns as int values and still preserve NaN values where they \n",
    "# exist, see this: https://stackoverflow.com/a/72323514. \n",
    "# The trick is: df = pd.read_csv('file.csv', dtype={'a': 'Int32', 'b': 'Int32'}), assuming that 'a' and 'b' \n",
    "# columns contain int and NaN values."
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the dataset (first steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Initial examination and adaptations\n",
    "- `<pd.df>.shape`, `<pd.df>.head()`, `<pd.df>.tail()`, `<pd.df>.sample()`, `<pd.df>.dtypes`, `<pd.df>.info()`, `<pd.df>.describe()`\n",
    "- `<pd.df>.loc[...]`, `<pd.df>.iloc[...]` - examine individual cells, columns, rows\n",
    "    - `loc` works with conditions and column names, `iloc` with numerical indices\n",
    "    - in both `loc` and `iloc`, multiple columns can be specified as a list of column names, and `:` in each index position means 'all'\n",
    "    - in `iloc`, both index positions can be specified as lists of numeric values\n",
    "- `<pd.df>.columns`, `<pd.df>.columns.values`, `<pd.df>.columns.values.tolist()` (or `<pd.df>.columns.values.to_list()`), `<pd.df>.values`\n",
    "- `<pd.df>.rename({'<column_1 old name>':'<column_1 new name>', '<column_2 old name>':'<column_2 new name>', ...}, axis='columns')`, `<pd.df>.columns = ['<column_1 name>', '<column_2 name>', ...]` (change the names of all columns in <pd.df>)\n",
    "- `ast.literal_eval()` (using Python's *ast* module to transform a string into a literal value, a list, a tuple or any other container object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### A sneak peek into the dataset\n",
    "- `<pd.df>.shape`, `<pd.df>.head()`, `<pd.df>.tail()`, `<pd.df>.sample()`, `<pd.df>.dtypes`, **<u>`<pd.df>.info()`**</u>, `<pd.df>.describe()` (shows descriptive statistics for numerical columns only).\n",
    "\n",
    "When calling `display()` on a method like `<pd.df>.head()`, `<pd.df>.tail()` and `<pd.df>.sample()`, only a certain default number of columns is displayed. To display *all* columns, use `pd.set_option('display.max_columns', None)` first. To display `<n>` columns, use `pd.set_option('display.max_columns', <n>)` first. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "songs.shape\n",
    "songs.head()\n",
    "songs.tail()\n",
    "songs.sample(10)\n",
    "songs.dtypes\n",
    "songs.info()\n",
    "songs.describe()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "songs.iloc[34, 12]\n",
    "songs.iloc[[245, 678, 789], [0, 1, 3]]\n",
    "songs.iloc[[245, 678, 789], :]\n",
    "songs.iloc[:, [0, 1, 3]]\n",
    "songs.loc[songs.Performer == 'The Beatles', ['Title', 'AlbumName', 'Performer']]\n",
    "songs.loc[songs['Performer'] == 'The Beatles', ['Title', 'AlbumName', 'Performer']]\n",
    "songs.loc[songs['Performer'] == 'The Beatles']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Columns\n",
    "- `<pd.df>.columns`, `<pd.df>.columns.values`, `<pd.df>.columns.values.tolist()` (or `<pd.df>.columns.values.to_list()`), `<pd.df>.values`\n",
    "\n",
    "Show the columns of the `songs` object (which is a `pd.DataFrame` object)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Get the columns as a pd.Index object, using <pd.df>.columns\n",
    "songs.columns\n",
    "# Get the columns as a list, using list(<pd.df>.columns)\n",
    "list(songs.columns)\n",
    "# Get the columns as a list, using <pd.df>.columns.tolist() or <pd.df>.columns.to_list()\n",
    "songs.columns.tolist()\n",
    "# Get the columns as a numpy.ndarray object, using <pd.df>.columns.values or np.array(<pd.df>.columns)\n",
    "songs.columns.values\n",
    "# Get the values of all items in the dataset as a numpy.ndarray of sequences of the values in each item, \n",
    "# using <pd.df>.values (the type of both the encompassing and the encompassed sequences is numpy.ndarray)\n",
    "songs.values\n",
    "songs.values[0]\n",
    "type(songs.values)\n",
    "type(songs.values[0])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Renaming columns\n",
    "- `<pd.df>.rename(columns={'<column_1 old name>':'<column_1 new name>', '<column_2 old name>':'<column_2 new name>', ...}, inplace=True)`, or\n",
    "- `<pd.df>.rename({'<column_1 old name>':'<column_1 new name>', '<column_2 old name>':'<column_2 new name>', ...}, axis='columns', inplace=True)`;\n",
    "- `<pd.df>.columns = ['<column_1 name>', '<column_2 name>', ...]` (change the names of all columns in `<pd.df>`)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Rename the names of some columns\n",
    "songs.rename(columns={'AlbumName': 'Album', 'Record Label': 'Record_label', 'Track.number': 'Track_number', \n",
    "                      'Song.duration': 'Duration', 'shake.the.audience': 'shake_the_audience', 'family.spiritual': 'family_spiritual'}, inplace=True)\n",
    "songs.columns\n",
    "# Rename these columns back to their original names\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Save the modified dataset\n",
    "songs.to_csv('../data/brit_col_renamed.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Adapt the data in columns to the usual formats"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Performer - strip everything after the performer name\n",
    "for i in range(len(songs)):\n",
    "    songs.iloc[i, 3] = songs.iloc[i, 3].split('\\n')[0].strip()\n",
    "songs.Performer"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Performer - get rid of the 'feat: ' prefix in some performer names\n",
    "\n",
    "# songs.loc[songs.Performer.str.startswith('feat: '), 'Performer']\n",
    "\n",
    "for i in range(len(songs)):\n",
    "    if songs.Performer[i].startswith('feat: '):\n",
    "        songs.iloc[i, 3] = songs.iloc[i, 3].split('feat: ')[1].strip()\n",
    "songs.loc[songs.Performer.str.startswith('feat: '), 'Performer']\n",
    "not any([p.startswith('feat: ') for p in songs.Performer])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Save the modified dataset\n",
    "songs.to_csv('../data/brit_performers_stripped.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Title - strip trailing blanks\n",
    "for i in range(len(songs)):\n",
    "    songs.iloc[i, 0] = songs.iloc[i, 0].rstrip()\n",
    "\n",
    "# # Alternatively\n",
    "# songs.Title = songs.Title.apply(lambda x: x.rstrip())\n",
    "\n",
    "# print(repr(songs.Title[4]))\n",
    "any([t.endswith(' ') for t in songs.Title])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Save the modified dataset\n",
    "songs.to_csv('../data/brit_titles_stripped.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Missing values and value counts\n",
    "- `sb.heatmap()`, e.g. `sb.heatmap(<pd.df>.isna(),cbar=False,cmap='viridis')` ([example](https://www.analyticsvidhya.com/blog/2021/08/how-to-perform-exploratory-data-analysis-a-guide-for-beginners/))\n",
    "- `<pd.df>.isna()` (`<pd.df>.isnull()`), `<pd.df>.isna().sum()` (`<pd.df>.isnull().sum()`) ([example](https://www.analyticsvidhya.com/blog/2021/08/how-to-perform-exploratory-data-analysis-a-guide-for-beginners/))\n",
    "- `<pd.df>['<column>'].value_counts()` (shows only the rows without NAs (default: dropna=True), check shape)\n",
    "- `<pd.df>['<column>'].value_counts(normalize=True)` (show proportions, rather than frequencies)\n",
    "- `<pd.df>.dropna(how='all'/'any', inplace=True)`, `<pd.Series>.dropna(how='all'/'any', inplace=True)` (return a new `<pd.Series>`/`<pd.Series>` object with missing values removed)\n",
    "\n",
    "The `cmap` parameter of `sb.heatmap()` denotes a [Matplotlib colormap](https://matplotlib.org/stable/tutorials/colors/colormaps.html#classes-of-colormaps) (`viridis`, `cividis`, `tab20`, `winter`, `BuPu_r`, `ocean`,...)."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Read the dataset\n",
    "songs = pd.read_csv('../data/brit_titles_stripped.csv')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Display the heatmap (missing values) of the songs dataset \n",
    "# (demonstrate using sb.heatmap() vs. sb.heatmap();)\n",
    "sb.heatmap(songs.isna(), cbar=False, cmap='cividis');"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many missing values are there? (`<pd.df>.isna().sum()` for all columns, `<pd.df>.['<column>'].isna().sum()` for a specific column, `<pd.df>.isna()[['<column1>', 'column2', ...]].sum()` for selected multiple columns; `isnull()` is the same as `isna()`, and `isna()` is used more often).\n",
    "\n",
    "Try also `<pd.df>.isna()`, `<pd.df>.isna()[['<column1>', 'column2', ...]]`, `type(<pd.df>.isna())`, `type(<pd.df>.isna().sum())`, `type(<pd.df>.isna()[['<column1>', 'column2', ...]].sum())`, `<pd.df>.isna().sum().value_counts()`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "songs.isna()\n",
    "songs.isna().sum()\n",
    "type(songs.isna().sum())\n",
    "songs.acousticness.isna().sum()\n",
    "songs.isna().acousticness.sum()\n",
    "songs.isna()[['Performer', 'acousticness', 'Duration']]\n",
    "songs.isna()[['Performer', 'acousticness', 'Duration']].sum()\n",
    "type(songs.isna()[['Performer', 'acousticness', 'Duration']].sum())\n",
    "songs.isna().sum().value_counts()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many missing values are there in the columns where there *are* missing values? `<i> = <pd.df>.isna().sum() > 0`, `<pd.df>.isna().sum()[<i>]`. \n",
    "Try also `<i>`, `type(<i>)`, `<i>[<i>]`, `<pd.df>.loc[:, <i>]`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# songs.isna().sum() > 0\n",
    "i = songs.isna().sum() > 0\n",
    "# i[i]\n",
    "# songs.loc[:, i]\n",
    "type(songs.isna().sum())\n",
    "songs.isna().sum()[i]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leave out rows with `np.NaN` values: `<pd.df>.dropna()`, `<pd.df>.<column>.dropna()`, `<pd.df>['<column>'].dropna()`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "songs.dropna()\n",
    "songs.dropna().isna().sum()\n",
    "songs.acousticness.isna().sum()\n",
    "songs.acousticness.dropna().isna().sum()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Show value counts for a dataframe: `<pd.df>.value_counts()`, `<pd.df>.value_counts(normalize=True)`."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "songs.value_counts()\n",
    "songs.value_counts(normalize=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "songs.value_counts()\n",
    "type(songs.value_counts())                                      # pd.Series\n",
    "songs.value_counts().index\n",
    "type(songs.value_counts().index)                                # a pd.MultiIndex object\n",
    "songs.value_counts().values\n",
    "len(songs.value_counts(dropna=False))                           # dropna=True by default"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Show duplicates (if any): `<pd.df>.duplicated()` (keeps the first occurrence by default), `<pd.df>.duplicated(keep=False)` (keeps all occurrences), `<pd.df>.<column>.duplicated()` (find duplicates based on a specific column), `<pd.df>.duplicated(subset=['<column 1>', '<column 2>',...])` (find duplicates based on multiple specific columns). \n",
    "\n",
    "Drop duplicates (if any): `<pd.df>.drop_duplicates(inplace=True)`."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "songs.duplicated()                                              # a pd.Series object with True for duplicates, False otherwise\n",
    "songs.loc[songs.duplicated(), ]                                 # careful, since duplicated() drops duplicates by default and the dimensions might not match\n",
    "songs.loc[songs.duplicated(keep=False), ]                       # keep ALL duplicates to match the dimensions; default: keep='first' \n",
    "# (https://stackoverflow.com/a/41786821)\n",
    "songs.loc[songs.value_counts(dropna=False).values > 1, ]        # another way to check if there are duplicates"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining individual data items, rows and columns\n",
    "- `<pd.df>.sample()`\n",
    "- Simple indexing and fancy indexing: `<pd.df>.iloc[]`, `<pd.df>.loc[]`\n",
    "- `<pd.df>.index`, `<pd.df>.index[<from>:<to>]`, `<pd.df>.reset_index(drop=True, inplace=True)`\n",
    "- Indexing using list of values: `<pd.df>.loc[<pd.df>.<column>.isin(<list of values>)]` (select those observations where the value of <column> is in the `<list of values>`)\n",
    "- Indexing in data stats: `<pd.df>.describe().loc['50%', '<column_name>']` (select the median of `<column_name>` from the `<pd.df>` stats computed by `describe()`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a sample of the dataset to get a feeling of what's in there."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "songs.sample(10)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the songs that have *some* missing values? \n",
    "Use masking to create the index of such elements; e.g. `<i>`, e.g., `<i> = songs.isna().sum() > 0` and show the type of the result (it's a `pd.Series` object).\n",
    "Display `<i>.index` and `<i>.values`. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "i = songs.isna().sum() > 0\n",
    "songs.isna().sum()[i]\n",
    "i.index\n",
    "i.values"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the `pd.Series` object `<i>` retrieved in the previous step, select the elements that have the values > 0 (i.e., the names of the columns that have some `NaN` values) - `<i>[<i>.values > 0]`, `<pd.df>.isna().sum()[i]`. \n",
    "Also, from the `<pd.df>` select a subset with only those columns that have *some* `NaN` values - `<pd.df>.loc[:, <i>]`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "songs.isna().sum()[i]\n",
    "songs.loc[:, i]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a `<pd.df>` select all rows that have *some* missing values: `<pd.df>[<pd.df>.isna().any(axis=1)]`, `<pd.df>.loc[<pd.df>.isna().any(axis=1)]`, `<pd.df>.loc[<pd.df>.isna().any(axis=1), :]`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "songs[songs.isna().any(axis=1)]\n",
    "songs.loc[songs.isna().any(axis=1)]\n",
    "songs.loc[songs.isna().any(axis=1), :]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Select rows based on column conditions: `<pd.df>.loc[<pd.df>.<column 1> == <...>]`, `<pd.df>.loc[(<pd.df>.<column 1> == <...>) & (<pd.df>.<column 2> == <...>)]`, etc. Notice the use of `&`, not `and`."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "songs.loc[songs.Duration.isna(), ]\n",
    "songs.loc[songs.Duration == '2:09', ]\n",
    "songs.loc[(songs.Duration == '2:09') & (songs.Title == 'Stay'), :]       # &, not and !!!"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the rows that have missing values in a specific column of a `<pd.df>`? For example, what are the songs with missing `Duration` values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `isna()`, `loc[]`, `iloc[]`, `len()` and `index`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling `loc[]` effectively means *creating a subset* (typically based on a relational or logical expression over one or more columns of the dataset). In other words, `loc[]` creates a *slice* of the dataframe, so the type of the result is `<pd.df>`.\n",
    "\n",
    "Note that `loc[]` works as `loc[<selected rows>, <selected columns>]`. The indices `<selected rows>` and `<selected columns>` can be created either directly in `loc[]` or beforehand.\n",
    "\n",
    "If defining the <selected rows> index to be used with `loc[]` subsequently, it is a good practice to define it as a boolean *mask* over a single column, like `<pd.df>['<column>'].isna()`, or as a logical expression in which each chunk is a relational expression over a single column, e.g. `<pd.df>['<column1>'].isna() & <pd.df>['<column2>'] < 23`. The result will be a subset of the original dataframe (i.e., another `<pd.df>`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the relevant index with a statement like `<pd.df>.loc[<pd.df>['<column>'].isna()].index` is a good starting point when using `iloc[]` subsequently.\n",
    "\n",
    "If using `iloc[]`, don't forget the `.index` chunk in the statement used to create the index (such as `<pd.df>.loc[<pd.df>['<column>'].isna()].index`). Without it, the result is another `<pd.df>`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Define i_iloc, the index to be used with iloc[], starting from <i> = <pd.df>['<column>'].isna();\n",
    "# iloc[] can be used conveniently here if the relevant index is already defined with <pd.df>.loc[<i>].index, i.e. <pd.df>.loc[<pd.df>['<column>'].isna()].index;\n",
    "# remember that the second index in iloc[] must be a number too (the relevant column index)\n",
    "i = songs.Duration.isna()\n",
    "i\n",
    "i[i]\n",
    "i_iloc = songs.loc[i].index\n",
    "i_iloc\n",
    "# # Alternatively\n",
    "# i_iloc = i[i].index\n",
    "# i_iloc\n",
    "songs.iloc[i_iloc, [0, 1, 3, 5]]\n",
    "\n",
    "# Define i_loc, the index (boolean mask) to be used with loc[]\n",
    "i_loc = songs.Duration.isna()\n",
    "songs.loc[i_loc, ['Title', 'Album', 'Performer', 'Duration']]\n",
    "\n",
    "# display(songs.loc[i_loc.index, ['Title', 'Album']])\n",
    "# display(songs.iloc[i_iloc, [0, 2]])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Replace `NaN` values in `Duration` with 'No' (`<pd.df>.loc[<i_loc>, '<column>'] = <new value>`, `<pd.df>.iloc[<i_iloc>, <column index>] = <new value>`)."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Make the replacement and display it\n",
    "songs.loc[i_loc, 'Duration'] = 'No'\n",
    "songs.loc[i_loc, ['Title', 'Album', 'Performer', 'Duration']]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-check the missing values now:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Use <pd.df>.Duration.isna().sum(), or <pd.df>.isna().sum()['Duration'] or sb.heatmap(<pd.df>.isna(), cmap='...')\n",
    "songs.Duration.isna().sum()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many songs from the beginning of The British Invasion are there?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Define the beginning of The British Invasion a list comprehension\n",
    "beginning = [y for y in range(1964, 1966)]\n",
    "# Display the songs from the early years using a combination of <pd.df>.loc[] and isin()\n",
    "songs.loc[songs.Year.isin(beginning), ['Title', 'Performer', 'Year']]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping and sorting data\n",
    "- `<pd.df>['<column>'].unique()`, `<pd.df>['<column>'].nunique()`\n",
    "- `<pd.df>.<column>.groupby()`, `<pd.df>.groupby('<column>')`, `<pd.df>.groupby('<column>').get_group(<value>)`\n",
    "- `<pd.df>['<column>'].value_counts()`, `<pd.df>['<column>'].value_counts().sort_index()`, `<pd.df>['<column>'].value_counts().sort_index(inplace=True)`\n",
    "- `<pd.df>.sort_values(by='<column name>', ascending=False/True)`\n",
    "- `<pd.df>.groupby('<column>').<another column>.<f()>.sort_values(ascending=False)` (aggregate using function `f()`, e.g. `mean()`)\n",
    "- `<pd.df>.groupby('<column>').<another column>.agg(['<f1 name>', '<f2 name>', ...])` (aggregate using multiple functions, e.g. `mean()`, `count()`,...)\n",
    "\n",
    "If `sort_values()` is used after `agg([<'f1 name>', '<f2 name>', ...])` (`agg(['<f1 name>', '<f2 name>', ...]).sort_values(by='<f name>', ascending=False)`), it must be passed one positional argument (`by='<f name>'`) before the optional `ascending=False`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many unique values for `Year` are there in the dataset (`<pd.df>['<column>'].unique()`, `<pd.df>.<column>.unique()`; `<pd.df>['<column>'].nunique()`, `<pd.df>.<column>.nunique()`)?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "songs.Year.unique()\n",
    "songs.Year.nunique()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group the songs in the dataset by the year of release (`<pd.df>.groupby('<column>')`). The result can be `songs_by_year`. Display it, show its type, and explore its individual groups and their types (`<pd.df>.groupby('<column>').get_group(<value>)`)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "songs_by_year = songs.groupby('Year')\n",
    "songs_by_year\n",
    "songs_by_year.get_group(1964)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many songs are there in the dataset for each `Year` (`<pd.df>['<column>'].value_counts()`, `<pd.df>['<column>'].value_counts()[<year>]`, `<pd.df>['<column>'].value_counts().sort_index()`)?\n",
    "\n",
    "Note that `value_counts()` returns a `pd.Series` object, with the index equal to `<pd.df>['<column>'].unique()` values."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "songs.Year.value_counts()\n",
    "songs.Year.value_counts()[1964]\n",
    "songs.Year.value_counts().sort_index()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the songs from the dataset by the year of release (`<pd.df>.sort_values(by='<column name>', ascending=False/True)`).\n",
    "(It is also possible to use `inplace=True` in `sort_values()`, but it will change the order of songs in the dataset from that point on.)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "songs.sort_values('Year', ascending=True)\n",
    "songs.sort_values('Year')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group the songs in the dataset by the year of release and display `mean` and/or `max` duration of the songs in each year, as well as the number (`count`) of songs in each year (`<pd.df>.groupby('<column>').<another column>.<f()>.sort_values(ascending=False)` (aggregate using function `f()`, e.g. `mean()`), `<pd.df>.groupby('<column>').<another column>.agg(['f1 name>', '<f2 name>', ...])` (aggregate using multiple functions, e.g. `mean()`, `count()`, `max()`,...)).\n",
    "If `sort_values()` is used after `agg([<'f1 name>', '<f2 name>', ...])` (`agg(['<f1 name>', '<f2 name>', ...]).sort_values(by='<f name>', ascending=False)`), it must be passed one positional argument (`by='<f name>'`) before the optional `ascending=False`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# To make all strings in songs.Duration look alike, insert placeholder values of the form 'mm:ss' \n",
    "# for those that are NaN, or that have been previously set to 'No', or the like\n",
    "i = songs.Duration == 'No'\n",
    "i[i]\n",
    "songs.loc[i, 'Duration'] = '0:18'\n",
    "# songs.loc[i, 'Duration']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Make sure that now all strings in songs.Duration are of the form 'mm:ss', i.e. they contain ':'\n",
    "# using len(songs.Duration.str.contains(':')) or all(songs.Duration.str.contains(':'))\n",
    "all(songs.Duration.str.contains(':'))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Convert Duration to int\n",
    "\n",
    "# Define to_sec() function that converts a single string of the form 'mm:ss' to int\n",
    "def to_int(s):\n",
    "    m, s = s.split(':')\n",
    "    return int(m) * 60 + int(s)\n",
    "# Use <pd.df>.<column>.apply(<function>) to convert the entire Duration column to int\n",
    "songs.Duration = songs.Duration.apply(to_int)\n",
    "songs.Duration"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Make the groupings and aggregations\n",
    "\n",
    "# <pd.df>.groupby('<column>').<another column>.<f()>.sort_values(ascending=False)\n",
    "songs.groupby('Year').Duration.mean()\n",
    "songs.groupby('Year').Duration.mean().sort_values(ascending=False)\n",
    "# <pd.df>.groupby('<column>').<another column>.agg(['<f1 name>', '<f2 name>', ...]).sort_values(by='<f name>', ascending=False)\n",
    "songs.groupby('Year').Duration.agg(['count', 'mean', 'max']).sort_values(by='count', ascending=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Data visualization\n",
    "Plot some scatterplots, line plots, bar graphs, histograms, scatterplots, box plots, violins, heatmaps,...\n",
    "[Example](https://www.analyticsvidhya.com/blog/2021/08/how-to-perform-exploratory-data-analysis-a-guide-for-beginners/)\n",
    "\n",
    "[Matplotlib examples](https://matplotlib.org/stable/gallery/index.html)\n",
    "\n",
    "[Seaborn examples](https://seaborn.pydata.org/examples/index.html) (see also [The Python Graph Gallery](https://www.python-graph-gallery.com/); it has a very neat user interface!)\n",
    "\n",
    "[Plotnine examples](https://plotnine.org/reference/) (click on any element for its API and examples)\n",
    "\n",
    "<u>**Note that it is also possible to**</u> <u>**[plot lines, bargraphs,... with Pandas only](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.line.html)**</u> (although in such cases Pandas interacts with Matplotlib under the hood)."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<b>IMPORTANT: Matplotlib terminology, Figure vs. Axes</b><br>\n",
    "A `Figure` object in Matplotlib is the outermost container for a Matplotlib graphic, which can contain multiple `Axes` objects. One source of confusion is the name: an `Axes` actually translates into what we think of as an individual plot or graph (rather than the plural of \"axis\", as we might expect)."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Missing values"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Read the dataset.\n",
    "\n",
    "`pd.read_csv()` returns a `pd.DataFrame` object.\n",
    "\n",
    "As for specifying the path of the dataset properly, see [this](https://stackoverflow.com/questions/35384358/how-to-open-my-files-in-data-folder-with-pandas-using-relative-path) (more specifically, **both** [this](https://stackoverflow.com/a/35384414/1899061) and [this](https://stackoverflow.com/a/43600253/1899061))."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Get the songs as a pd.DataFrame object from 'data/brit_titles_stripped.csv', \n",
    "# or from '../data/brit_titles_stripped.csv', or '../../data/brit_titles_stripped.csv', or ...,\n",
    "# depending on where the csv file is located\n",
    "songs = pd.read_csv('../data/brit_titles_stripped.csv')\n",
    "songs"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Check for missing values (use, e.g., `sb.heatmap(<pd.df>.isna(), cbar=False, cmap='viridis')`)."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "sb.heatmap(songs.isna(), cbar=False, cmap='viridis');",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Briefly analyze the rows with `NaN`s. To select all such rows, use `any()` (`<pd.df>.loc[<pd.df>.isna().any(axis=1), ['<column 1>', '<column 2>', ...]`). To select the rows where there are no `NaN`s at all, use `<pd.df>.loc[<pd.df>.notna().all(axis=1), ['<column 1>', '<column 2>', ...]`."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "songs.loc[songs.isna().any(axis=1), ['Title', 'Performer', 'Duration', 'danceability']]",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "It is difficult to spot any regular pattern, so get rid of `NaN`s in the simplest way possible (`<pd.df>.dropna(inplace=True)`). Make sure that the modified dataset is `NaN`-free (`<pd.df>.isna().sum()`)."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "songs.dropna(inplace=True)\n",
    "songs\n",
    "songs.isna().sum()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Save the reduced dataset as `brit_visualization.csv`, the starting one to make visualizations."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Save the modified dataset\n",
    "songs.to_csv('../data/brit_visualization.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Scatterplot"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Read the modified dataset (if necessary).\n",
    "\n",
    "`pd.read_csv()` returns a `pd.DataFrame` object.\n",
    "\n",
    "As for specifying the path of the dataset properly, see [this](https://stackoverflow.com/questions/35384358/how-to-open-my-files-in-data-folder-with-pandas-using-relative-path) (more specifically, **both** [this](https://stackoverflow.com/a/35384414/1899061) and [this](https://stackoverflow.com/a/43600253/1899061))."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "songs = pd.read_csv('../data/brit_visualization.csv')\n",
    "songs"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Scatterplot the relationship between `Duration` and `danceability`."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Change the format of `Duration` from `str` to `int`."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def to_int(s):\n",
    "    m, s = s.split(':')\n",
    "    return int(m) * 60 + int(s)\n",
    "songs.Duration = songs.Duration.apply(to_int)\n",
    "songs.Duration"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Save the modified dataset as `brit_visualization_duration_int.csv`."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Save the modified dataset\n",
    "songs.to_csv('../data/brit_visualization_duration_int.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "To set the ranges of values on x-axis and y-axis (`Duration`, `danceability`), check the max values or run `describe()`."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "max(songs.Duration)\n",
    "songs.describe()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "###### 1. Matplotlib version"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "[Matplotlib scatterplot example](https://matplotlib.org/stable/gallery/shapes_and_collections/scatter.html)<br>\n",
    "[Excellent tutorial on matplotlib](https://realpython.com/python-matplotlib-guide/)\n",
    "\n",
    "Use the following syntax:<br>\n",
    "`ax = plt.axes()`<br>\n",
    "`ax.set(xlim=(<from>, <to>), ylim=(<from>, <to>), xlabel='<xlabel>', ylabel='<ylabel>', title='<title>')`<br>\n",
    "`ax.scatter(<pd.df>['<X>'], <pd.df>['<Y>'], marker='<marker type>', c='<fill color>', edgecolors='<edgecolor>', s=<marker size>)`; <br>\n",
    "\n",
    "The `<pd.df>['<X>']` and `<pd.df>['<Y>']` arguments can be also specified as `<pd.df>.<X>` and `<pd.df>.<Y>` if `<X>` and `<Y>` are single words.\n",
    "The color parameter (`c`) is optional; if present, it should be a scalar or a sequence of length consistent with the lengths of `<X>` and `<Y>` (`(<X>, <Y>)` points). The `marker` parameter is optional as well. Both `c` and `marker` have defaults. For other values of `c` and `marker`, see [this](https://matplotlib.org/stable/gallery/color/named_colors.html#css-colors) and [this](https://matplotlib.org/stable/api/_as_gen/matplotlib.markers.MarkerStyle.html#matplotlib.markers.MarkerStyle.markers), respectively. A good value for `s` is 30-40 for 200-300 markers on the plot.\n",
    "\n",
    "Alternatively:<br>\n",
    "`ax.plot(<pd.df>['<X>'], <pd.df>['<Y>'], marker='<marker type>', color='<color>', linestyle='');`<br>\n",
    "\n",
    "The `linestyle=''` parameter is essential for plotting the dots only - omitting it means that the connecting lines are plotted as well."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ax = plt.axes()\n",
    "# ax;\n",
    "ax.set(xlim=(50, 700), ylim=(0, 1), xlabel='Duration', ylabel='danceability', title='danceability(Duration)')\n",
    "ax;\n",
    "# ax.scatter(x=songs.Duration, y=songs.danceability)\n",
    "ax.scatter(x=songs.Duration, y=songs.danceability, c='yellow', edgecolors='black', marker='o');"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "###### 2. Plotnine version\n",
    "[Plotnine scatterplot example](https://plotnine.org/reference/geom_point.html#plotnine.geom_point)<br>\n",
    "[Excellent tutorial on plotnine](https://realpython.com/ggplot-python/)\n",
    "\n",
    "\n",
    "In *Plotnine*, the syntax for setting the ranges on x and y axes is `xlim(<from>, <to>)`, `ylim(<from>, <to>)` (as two separate lines in calling `ggplot()`), or, alternatively, `coord_cartesian(xlim=(<from>, <to>), ylim=(<from>, <to>))` as a single separate line."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "If `<x>` and `<y>` values are not columns of a dataframe already (`<X>` and `<Y>`), create a minimal dataframe to support plotting (`<df> = pd.DataFrame({'<X>': <x>, '<Y>': <y>})`)."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Use `ggplot` as:\n",
    "\n",
    "`(`<br>\n",
    "&emsp;&emsp;`ggplot(<df>, aes(x='<X>', y='<Y>) +`<br>\n",
    "&emsp;&emsp;`geom_point(color='<color>', fill='<fill color>', shape='<shape>', size=<size>) +`<br>\n",
    "&emsp;&emsp;`coord_cartesian(xlim=(<from>, <to>), ylim=(<from>, <to>)) +`<br>\n",
    "&emsp;&emsp;`theme(figure_size=(10, 7), dpi=60, axis_text_x=element_text(color='<color>, size=<size>), axis_text_y=element_text(color='<color>, size=<size>)) +`<br>\n",
    "&emsp;&emsp;`labs(x='...', y='...', title='...')`<br>\n",
    "`).draw()`\n",
    "\n",
    "The `color`, `fill` and `shape` parameters have defaults. The other values of these parameters are the same as in Matplotlib (see [this](https://matplotlib.org/stable/gallery/color/named_colors.html) and [this](https://matplotlib.org/stable/api/_as_gen/matplotlib.markers.MarkerStyle.html#matplotlib.markers.MarkerStyle), respectively).\n",
    "\n",
    "In `theme(figure_size=(10, 7), dpi=60, ...)`, the `dpi` parameter is necessary to achieve full control over the plot size (`figure_size` is not enough). It is a good idea to experiment with the actual values for `figure_size`and `dpi`. \n",
    "\n",
    "Another useful parameter of `theme()` is `axis_text_x=element_text(color='<color>, size=<size>)` (and `axis_text_y=element_text(color='<color>, size=<size>)`). It controls the parameters of the axes text. Similarly, `axis_title=element_text(color='<color>, size=<size>)` can be used in `theme()` to set the color and font size of axis labels (<b>both simultaneously!</b>), `axis_title_x=element_text(color='<color>, size=<size>)` (and `axis_title_y=element_text(color='<color>, size=<size>)`) change the color and font size of x-axis label (y-axis label), and `title=element_text(color='<color>, size=<size>)` do the same for the plot title.\n",
    "\n",
    "**Note 1:** `aes(x='<X>', y='<Y>)` shows compiler errors but works anyway; `aes('<X>', '<Y>)` does not show any compiler error. However, `labs(x='...', y='...', title='...')` shows compiler errors regardless of `x=...`, `y=...`, ..., but works only *with* `x=...`, `y=...`. To eliminate these compiler errors, use `xlab('...')`, `ylab('...')` and `ggtitle('...')` as separate lines after calling `ggplot()`. \n",
    "\n",
    "**Note 2:** Once the figure size is changed for plotnine graphs by calling `theme(figure_size=(10, 7), dpi=60)` or similar, the Matplotlib graphs use the new figure size as well. To change it, use `plt.figure(figsize=...)` in the code for Matplotlib graphs. "
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "(\n",
    "    ggplot(songs, aes(x='Duration', y='danceability')) +\n",
    "    theme(figure_size=(8, 5), dpi=60) + \n",
    "    geom_point(color='black', fill='yellow', ) + \n",
    "    # xlab('Duration') + \n",
    "    # ylab('danceability') + \n",
    "    # ggtitle('danceability(Duration)')\n",
    "    labs(x='Duration', y='danceability', title='danceability(Duration)')\n",
    ").draw()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "###### 3. A brief analysis of the plot: What are the shortest/longest songs and their durations?"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# display(<pd.df>['column'] <= <value>)                                    # Boolean mask\n",
    "# display(type(<pd.df>['column'] <= <value>))                              # pd.Series\n",
    "# display(<pd.df>[<pd.df>['column'] <= <value>]['column to to display'])   # select one column\n",
    "# display(<pd.df>[<pd.df>['column'] <= <value>]['column 1  to to display', 'column 2 to display',...])   # select multiple columns\n",
    "\n",
    "# Try this also with .loc[], as well as with .iloc[], with an explicitly set index and with .index\n",
    "\n",
    "songs.loc[songs.Duration > 300, ['Title', 'Performer', 'Album', 'Year', 'Duration']]\n",
    "songs.loc[songs.Duration < 90, ['Title', 'Performer', 'Album', 'Year', 'Duration']]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Line plot"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Read the modified dataset (if necessary).\n",
    "\n",
    "`pd.read_csv()` returns a `pd.DataFrame` object.\n",
    "\n",
    "As for specifying the path of the dataset properly, see [this](https://stackoverflow.com/questions/35384358/how-to-open-my-files-in-data-folder-with-pandas-using-relative-path) (more specifically, **both** [this](https://stackoverflow.com/a/35384414/1899061) and [this](https://stackoverflow.com/a/43600253/1899061))."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "songs = pd.read_csv('../data/brit_visualization_duration_int.csv')\n",
    "songs"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "How many songs from each `Year` are there?"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Use <pd.df>['<column>'].value_counts(), <pd.df>['<column>'].value_counts()[<specific value> in <column>]\n",
    "songs.Year.value_counts()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Sort this result by index: `pd.Series.sort_index()` (there is also `pd.DataFrame.sort_index()`)."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define val_counts_sorted_by_index\n",
    "val_counts_sorted_by_index = songs.Year.value_counts().sort_index()\n",
    "val_counts_sorted_by_index"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Preparation for plotting (`counts` on y-axis, `year` on x-axis): get the `np.ndarray` version of `val_counts_sorted_by_index`, as well as of its index.\n",
    "\n",
    "One way of doing it is to use `np.array()` over `val_counts_sorted_by_index.index` and `val_counts_sorted_by_index.values`. However, the same effect is achieved using only `val_counts_sorted_by_index.index` and `val_counts_sorted_by_index.values` (their type is `np.ndarray`)."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "years = val_counts_sorted_by_index.index\n",
    "counts = val_counts_sorted_by_index.values"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "And now plot it."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "###### 1. Matplotlib version\n",
    "[Matplotlib line plot example](https://matplotlib.org/stable/gallery/lines_bars_and_markers/simple_plot.html)<br>\n",
    "[Excellent tutorial on matplotlib](https://realpython.com/python-matplotlib-guide/)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<em>Initial version</em><br>\n",
    "\n",
    "`ax = plt.axes()`<br>\n",
    "`ax.set(xlim=(<lower limit>, <upper limit>), ylim=(<lower limit>, <upper limit>), xlabel='...', ylabel='...', title='...')`<br>\n",
    "`ax.ticklabel_format(useOffset=False)`<br>\n",
    "`ax.plot(<x>, <y>, color='...', marker='<marker type>', linewidth=<number>, alpha=<number>)`<br>\n",
    "\n",
    "To prevent numbers displayed in scientific notation (exponential) on axes ticks, make sure to use `ax.ticklabel_format(useOffset=False)`.\n",
    "\n",
    "Do not use `x=<x>, y=<y>` in `ax.plot()`, it generates an error. Use just `<x>, <y>`. For the other parameters, the keywords are necessary.\n",
    "\n",
    "Examples of parameters in `ax.plot()`: `color='steelblue'`, `linewidth=3`, `alpha=0.8` (alpha: transparency (0-1)).\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Initial version\n",
    "ax = plt.axes()\n",
    "ax.set(xlim=(1963, 1968), ylim=(150, 400), xlabel='year', ylabel='count', title='Number of songs by year')\n",
    "ax.ticklabel_format(useOffset=False)\n",
    "ax.plot(years, counts, color='steelblue', linewidth=2, alpha=0.8);"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<em>Elaborated version 1 (without `plt.subplots()`)</em><br>\n",
    "\n",
    "`plt.figure(layout='constrained', facecolor='<color>', figsize=(<x_size>, <y_size>))`&emsp;&emsp;# Set the Figure object parameters<br><br>\n",
    "`ax = plt.axes()`&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;# Get the Axes object<br>\n",
    "`ax.set_facecolor('<color>')`&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;# Set the Axes object parameters<br>\n",
    "`ax.set_title('<title>', fontsize=12, loc='left')`<br>\n",
    "`ax.set_xlabel('<x_label>', fontsize=8)`<br>\n",
    "`ax.set_ylabel('<y_label>', fontsize=8)`<br>\n",
    "\n",
    "`ax.set(xlim=(<m>, <n>), ylim=(<p>, <q>))`&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;# Without `plt.subplots()`, `xlim` and `ylim` have to be set using `ax.set()`<br>\n",
    "\n",
    "`ax.ticklabel_format(useOffset=False)`&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;# Set the tick parameters<br>\n",
    "`ax.tick_params(axis='x', labelsize=6)`<br>\n",
    "`ax.tick_params(axis='y', labelsize=6)`<br>\n",
    "\n",
    "`ax.plot(years, counts, color='<color>', linewidth=2, alpha=0.8);`&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;# Display the plot using `ax.plot()`<br>\n",
    "\n",
    "In `plt.figure(layout='constrained', facecolor='<color>', figsize=(<x_size>, <y_size>))`, using `layout='constrained'` is recommended to avoid overlapping of figure elements when changing the figure size. For a good figure size, use `figsize=(3.5, 2)` or similar.\n",
    "\n",
    "It is also possible to set the Axes object background color using `plt.axes(facecolor='<color>')` instead of `ax.set_facecolor('<color>')`.\n",
    "\n",
    "To prevent numbers displayed in scientific notation (exponential) on axes ticks, make sure to use `ax.ticklabel_format(useOffset=False)`.\n",
    "\n",
    "Experiment with different font sizes for labels, title and ticks.\n",
    "\n",
    "Do not use `x=<x>, y=<y>` in `ax.plot()`, it generates an error. Use just `<x>, <y>`. For the other parameters, the keywords are necessary.\n",
    "\n",
    "Examples of parameters in `ax.plot()`: `color='steelblue'`, `linewidth=3`, `alpha=0.8` (alpha: transparency (0-1))."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Elaborated version 1 (without plt.subplots())\n",
    "\n",
    "# Set the Figure object parameters\n",
    "plt.figure(layout='constrained', facecolor='lightgreen', figsize=(3.5, 2), )\n",
    "# Get the Axes object\n",
    "ax = plt.axes()\n",
    "# Set the Axes object parameters\n",
    "ax.set_facecolor('lightyellow')\n",
    "ax.set_title('Number of songs by year', fontsize=12)\n",
    "ax.set_xlabel('year', fontsize=8)\n",
    "ax.set_ylabel('counts', fontsize=8)\n",
    "# Without plt.subplots(), xlim and ylim have to be set using ax.set()\n",
    "ax.set(xlim=(1963, 1968), ylim=(150, 400))\n",
    "# Set the tick parameters\n",
    "ax.ticklabel_format(useOffset=False)\n",
    "ax.tick_params(axis='x', labelsize=6)\n",
    "ax.tick_params(axis='y', labelsize=6)\n",
    "# Display the plot using ax.plot()\n",
    "ax.plot(years, counts, color='steelblue', linewidth=2, alpha=0.8);"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<em>Elaborated version 2 (with `plt.subplots()`)</em><br>\n",
    "\n",
    "`fig, ax = plt.subplots(1, 1, layout='constrained', facecolor='color', figsize=(<x_size>, <y_size>))`&emsp;&emsp;# Get the Figure and the Axes objects<br>\n",
    "\n",
    "`ax.plot(years, counts, color='<color>', linewidth=2, alpha=0.8)`&emsp;&emsp;&emsp;# Plot the data on the Axes<br>\n",
    "\n",
    "`ax.set_title('<Title>', fontsize=12, loc='left')`&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&nbsp;# Set the Axes title, background color (face color), labels (incl. font sizes) and limits<br>\n",
    "`ax.set_facecolor('<color>')`<br>\n",
    "`ax.set_xlabel('<x_label>', fontsize=8)`<br>\n",
    "`ax.set_ylabel('<y_label>', fontsize=8)`<br>\n",
    "`ax.set_xlim(<m>, <n>)`<br>\n",
    "`ax.set_ylim(<p>, <q>)`<br>\n",
    "\n",
    "`ax.ticklabel_format(useOffset=False)`&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;# Set the tick parameters<br>\n",
    "`ax.tick_params(axis='x', labelsize=6)`<br>\n",
    "`ax.tick_params(axis='y', labelsize=6)`<br>\n",
    "\n",
    "`ax.plot(years, counts, color='steelblue', linewidth=2, alpha=0.8);`&emsp;&emsp;# Display the plot using `ax.plot()`<br>\n",
    "\n",
    "In `fig, ax = plt.subplots(1, 1, layout='constrained', facecolor='color', figsize=(<x_size>, <y_size>))`, using `layout='constrained'` is recommended to avoid overlapping of figure elements when changing the figure size. For a good figure size, use `figsize=(3.5, 2)` or similar.\n",
    "\n",
    "To prevent numbers displayed in scientific notation (exponential) on axes ticks, make sure to use `ax.ticklabel_format(useOffset=False)`.\n",
    "\n",
    "Experiment with different font sizes for labels, title and ticks.\n",
    "\n",
    "Do not use `x=<x>, y=<y>` in `ax.plot()`, it generates an error. Use just `<x>, <y>`. For the other parameters, the keywords are necessary.\n",
    "\n",
    "Examples of parameters in `ax.plot()`: `color='steelblue'`, `linewidth=3`, `alpha=0.8` (alpha: transparency (0-1))."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Get the Figure and the Axes objects\n",
    "fig, ax = plt.subplots(1, 1, layout='constrained', facecolor='lightgreen', figsize=(3.5, 2))\n",
    "# Plot the data on the Axes\n",
    "ax.plot(years, counts, color='steelblue', linewidth=2, alpha=0.8)\n",
    "# Set the Axes title, labels (incl. font sizes) and limits\n",
    "ax.set_title('Number of songs by year', fontsize=10)\n",
    "ax.set_xlabel('year', fontsize=8)\n",
    "ax.set_ylabel('counts', fontsize=8)\n",
    "ax.set_xlim(1963, 1968)\n",
    "ax.set_ylim(150, 400)\n",
    "# Set the Axes background color (face color) \n",
    "ax.set_facecolor('lightyellow')\n",
    "# Set the tick parameters\n",
    "ax.ticklabel_format(useOffset=False)\n",
    "ax.tick_params(axis='x', labelsize=6)\n",
    "ax.tick_params(axis='y', labelsize=6)\n",
    "# Display the plot using plt.show()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "###### 2. Plotnine version\n",
    "[Plotnine line plot example](https://plotnine.org/reference/geom_line.html#plotnine.geom_line)<br>\n",
    "[Excellent tutorial on plotnine](https://realpython.com/ggplot-python/)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "For some reason, running the Matplotlib version immediately before running the Plotnine version sometimes resets all values in `years` to 1970 (!!!), so re-creating `years` here might be necessary."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# years = np.array(val_counts_sorted_by_index.index)\n",
    "# display(years)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "If `<x>` and `<y>` values are not in a dataframe columns (`<X>` and `<Y>`) already, create a minimal dataframe to support plotting (`<df> = pd.DataFrame({'<X>': <x>, '<Y>': <y>})`)."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = pd.DataFrame({'Years': years, 'Counts': counts})\n",
    "df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Use `ggplot` as:\n",
    "\n",
    "`(`<br>\n",
    "&emsp;&emsp;`ggplot(<df>, aes(x='<X>', y='<Y>) +`<br>\n",
    "&emsp;&emsp;`geom_line(color='<color>', size=<size>, alpha=<transparency, 0-1>, linetype='<linetype>') +`<br>\n",
    "&emsp;&emsp;`coord_cartesian(xlim=(<from>, <to>), ylim=(<from>, <to>)) +`<br>\n",
    "&emsp;&emsp;`theme(figure_size=(10, 7), dpi=60, axis_text_x=element_text(color='<color>, size=<size>), axis_text_y=element_text(color='<color>, size=<size>)) +`<br>\n",
    "&emsp;&emsp;`labs(x='...', y='...', title='...')`<br>\n",
    "`).draw()`\n",
    "\n",
    "The `color`, `size` and `linetype` parameters have defaults. The other values of these parameters are pretty much the same as in Matplotlib (see [this](https://matplotlib.org/stable/gallery/color/named_colors.html) and [this](https://matplotlib.org/stable/gallery/lines_bars_and_markers/linestyles.html), respectively).\n",
    "\n",
    "In `theme(figure_size=(10, 7), dpi=60, ...)`, the `dpi` parameter is necessary to achieve full control over the plot size (`figure_size` is not enough). It is a good idea to experiment with the actual values for `figure_size`and `dpi`. \n",
    "\n",
    "Another useful parameter of `theme()` is `axis_text_x=element_text(color='<color>, size=<size>)` (and `axis_text_y=element_text(color='<color>, size=<size>)`). It controls the parameters of the axes text. Similarly, `axis_title=element_text(color='<color>, size=<size>)` can be used in `theme()` to set the color and font size of axis labels (<b>both simultaneously!</b>), `axis_title_x=element_text(color='<color>, size=<size>)` (and `axis_title_y=element_text(color='<color>, size=<size>)`) change the color and font size of x-axis label (y-axis label), and `title=element_text(color='<color>, size=<size>)` do the same for the plot title.\n",
    "\n",
    "**Note 1:** `aes(x='<X>', y='<Y>)` shows compiler errors but works anyway; `aes('<X>', '<Y>)` does not show any compiler error. However, `labs(x='...', y='...', title='...')` shows compiler errors regardless of `x=...`, `y=...`, ..., but works only *with* `x=...`, `y=...`. To eliminate these compiler errors, use `xlab('...')`, `ylab('...')` and `ggtitle('...')` as separate lines after calling `ggplot()`. \n",
    "\n",
    "**Note 2:** Once the figure size is changed for plotnine graphs by calling `theme(figure_size=(10, 7), dpi=60)` or similar, the Matplotlib graphs use the new figure size as well. To change it, use `plt.figure(figsize=...)` in the code for subsequent Matplotlib graphs. \n",
    "\n",
    "Examples of parameters in geom_line(): color='steelblue', size=1, linetype='solid', alpha=0.8 (alpha: transparency (0-1))."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "(\n",
    "    ggplot(df, aes(x='Years', y='Counts')) + \n",
    "    geom_line() +\n",
    "    theme(figure_size=(6, 4), dpi=60)\n",
    ").draw()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "(\n",
    "    ggplot(df, aes(x='Years', y='Counts')) + \n",
    "    geom_line(color='red', linetype='--') + \n",
    "    geom_point(color='grey', fill='red') +\n",
    "    theme(figure_size=(6, 4), dpi=60) + \n",
    "    labs(x='year', y='count', title='Number of songs by year')\n",
    ").draw()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "###### 3. Smoothen the curves\n",
    "Based on [this](https://stackoverflow.com/a/5284038/1899061).<br><br>\n",
    "`from scipy.interpolate import make_interp_spline, BSpline`<br>\n",
    "\n",
    "`<x> = <definition of x-axis variable>`<br>\n",
    "`<y> = <definition of y-axis variable>`<br>\n",
    "\n",
    "`<x_smooth> = np.linspace(<x>.min(), <x>max(), 300)`&emsp;&emsp;&emsp;&emsp;# 300: the number of points to make between `<x>.min() and <x>.max()`<br>\n",
    "`spl = make_interp_spline(year, counts, k=3)`&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; # type: BSpline<br>\n",
    "`<y_smooth> = spl(<x>_smooth)`<br>\n",
    "\n",
    "`plt.xlim([<lowest value of x to show on the plot>, <highest value of x to show on the plot>])`<br>\n",
    "`plt.ylim([<lowest value of y to show on the plot>, <highest value of x to show on the plot>])`<br>\n",
    "\n",
    "`plt.plot(<x_smooth>, <y_smooth>)`<br>\n",
    "`plt.plot(<x>, <y>)`&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;# optional: show the segmented line on the same plot as well<br>\n",
    "`plt.show()`\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# # 300 represents the number of points to make between T.min and T.max\n",
    "# T = np.array([6, 7, 8, 9, 10, 11, 12])\n",
    "# power = np.array([1.53E+03, 5.92E+02, 2.04E+02, 7.24E+01, 2.72E+01, 1.10E+01, 4.70E+00])\n",
    "#\n",
    "# # plt.plot(T,power)\n",
    "# # plt.show()\n",
    "#\n",
    "# xnew = np.linspace(T.min(), T.max(), 300)\n",
    "#\n",
    "# spl = make_interp_spline(T, power, k=3)  # type: BSpline\n",
    "# power_smooth = spl(xnew)\n",
    "#\n",
    "# plt.plot(xnew, power_smooth)\n",
    "# plt.show()\n",
    "\n",
    "# from scipy.interpolate import make_interp_spline, BSpline\n",
    "# \n",
    "# year_smooth = np.linspace(years.min(), years.max(), 300)\n",
    "# spl = make_interp_spline(years, counts, k=3)  # type: BSpline\n",
    "# counts_smooth = spl(year_smooth)\n",
    "# \n",
    "# # plt.figure(layout='constrained', figsize=(5, 3), facecolor='lightyellow', alpha=0.5)\n",
    "# fig, ax = plt.subplots(figsize=(5, 3), layout='constrained', facecolor='beige')\n",
    "# \n",
    "# ax.set_facecolor('navajowhite')\n",
    "# \n",
    "# plt.ticklabel_format(useOffset=False)\n",
    "# \n",
    "# plt.xlim([1963, 1968])\n",
    "# plt.ylim([150, 400])\n",
    "# plt.xticks(fontsize=8)\n",
    "# plt.yticks(fontsize=8)\n",
    "# \n",
    "# plt.xlabel('year', fontsize=10)\n",
    "# plt.ylabel('count', fontsize=10)\n",
    "# plt.title('Song counts over years', fontsize=12, color='green')\n",
    "# \n",
    "# plt.plot(year_smooth, counts_smooth)\n",
    "# plt.plot(years, counts)\n",
    "# plt.show()\n",
    "\n",
    "# # Alternatively\n",
    "# ax = plt.axes()\n",
    "# ax.set(xlim=(years.min()-1, years.max()+1), ylim=(150, 400), xlabel='year', ylabel='count', title='Song counts over years')\n",
    "# ax.ticklabel_format(useOffset=False)\n",
    "# ax.plot(years, counts, color='steelblue', linewidth=2, marker='o', alpha=0.8)\n",
    "# ax.plot(year_smooth, counts_smooth, color='green', linewidth=2, alpha=0.8);"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "###### 4. Multiple subplots\n",
    "(shown here after [this](https://jakevdp.github.io/PythonDataScienceHandbook/04.08-multiple-subplots.html))"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# # From https://jakevdp.github.io/PythonDataScienceHandbook/04.08-multiple-subplots.html\n",
    "# fig = plt.figure()\n",
    "# ax1 = fig.add_axes([0.1, 0.55, 0.8, 0.4],\n",
    "#                    xticklabels=[], ylim=(-1.2, 1.2))\n",
    "# ax2 = fig.add_axes([0.1, 0.1, 0.8, 0.4],\n",
    "#                    ylim=(-1.2, 1.2))\n",
    "# # Meanings of the numbers in [0.1, 0.55, 0.8, 0.4]:\n",
    "# #     0.1 - distance from the left edge of fig (grey area)\n",
    "# #     0.55 - distance between the upper and lower subplots (0.5: they touch each other)\n",
    "# #     0.8 - distance from the right edge of fig (grey area)\n",
    "# #     0.4 - area assigned to the upper/lower subplot (ax1/ax2) along the vertical axes\n",
    "# # Experiment with these numbers to get a better feeling for them\n",
    "\n",
    "# x = np.linspace(0, 10)\n",
    "# ax1.plot(np.sin(x))\n",
    "# ax2.plot(np.cos(x));\n",
    "# \n",
    "# fig, ax = plt.subplots()\n",
    "# ax\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(6, 6), )\n",
    "# fig\n",
    "ax1 = fig.add_axes([0.1, 0.579, 0.8, 0.35],\n",
    "                   xlim=(1963, 1968), ylim=(150, 400),\n",
    "                   xlabel='year', ylabel='counts',\n",
    "                   title='Number of songs recorded over the years')\n",
    "ax2 = fig.add_axes([0.1, 0.08, 0.8, 0.35],\n",
    "                   xlim=(1963, 1968), ylim=(150, 400),\n",
    "                   xlabel='year', ylabel='counts',\n",
    "                   title='Number of songs recorded over the years')\n",
    "# display(type(ax1))\n",
    "ax1.ticklabel_format(useOffset=False)\n",
    "ax2.ticklabel_format(useOffset=False)\n",
    "\n",
    "ax1.plot(years, counts, color='steelblue', linewidth=1.5, alpha=0.8)    # alpha: transparency (0-1)\n",
    "ax2.plot(years, counts, color='purple', linewidth=1.5, alpha=0.8);      # alpha: transparency (0-1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Histogram"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Read the dataset (`brit_visualization_duration_int.csv`)."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "songs = pd.read_csv('../data/brit_visualization_duration_int.csv')",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Plot the histogram of song durations (lengths, times)."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Use Pandas to extract song lengths as a `pd.Series` object (`<pd.Series object> = <pd.df>['<column>']`)."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Get the song lengths as a pd.Series object\n",
    "duration = songs.Duration"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Convert the song lengths into a NumPy array (using <song lengths>.to_numpy(), or np.array(<song lengths>), or <song lengths>.values)\n",
    "type(duration)\n",
    "type(duration.values)\n",
    "duration = duration.values\n",
    "duration"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "###### 1. Matplotlib version\n",
    "[Matplotlib histogram example](https://matplotlib.org/stable/gallery/statistics/hist.html)\n",
    "\n",
    "Plot the histogram of the song lengths using Matplotlib.\n",
    "\n",
    "Minimal version: `plt.hist(<x>, bins=<number of bins>);` or `sb.histplot(<x>, bins=<number of bins>)`.\n",
    "\n",
    "Alternatively:<br>\n",
    "`plt.figure(layout='constrained', facecolor='<color>', figsize=(3.5, 2), )`<br>\n",
    "`ax = plt.axes()`<br>\n",
    "`ax.set(xlabel='...', ylabel='...', title='...')`<br>\n",
    "`ax.hist(<x>, bins=<number of bins>)`<br>\n",
    "\n",
    "As for the plot styles, there are a lot of [available styles](https://www.dunderdata.com/blog/view-all-available-matplotlib-styles) that can be also shown in code using `plt.style.available`. See also [this](https://www.analyticsvidhya.com/blog/2021/08/exploring-matplotlib-stylesheets-for-data-visualization/).\n",
    "\n",
    "Alternatively, plot style can be set using `sb.set_theme(palette='...')` (or just `sb.set()`, but that function might get deprecated and removed from *Seaborn* in the future). See [`sb.set_theme()` documentation](https://seaborn.pydata.org/generated/seaborn.set_theme.html) for the function's parameters and defaults. For `palette='...'` use any of the palettes shown with `plt.style.available`, or any of [these](https://matplotlib.org/stable/users/explain/colors/colormaps.html#qualitative), or..."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Set plot style using sb.set_theme(palette='Pastel2')\n",
    "sb.set_theme(palette='Pastel2')\n",
    "\n",
    "# Plot the histogram - x: song time in [sec]; y: number of songs; 40 bins\n",
    "\n",
    "# # Minimal version\n",
    "# plt.hist(duration, bins=40);\n",
    "# sb.histplot(duration, bins=40);\n",
    "\n",
    "# A more detailed version\n",
    "plt.figure(layout='constrained', facecolor='lightgreen', figsize=(3.5, 2), )\n",
    "ax=plt.axes()\n",
    "ax.set(xlabel='duration', ylabel='count', title='Song duration histogram')\n",
    "ax.hist(duration, bins=40);"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "###### 2. Plotnine version\n",
    "[Plotnine histogram example](https://plotnine.org/reference/geom_histogram.html#plotnine.geom_histogram)\n",
    "\n",
    "Plot the histogram of the song lengths using *Plotnine*.\n",
    "\n",
    "A minimal, but effective version:<br>\n",
    "`plot = ggplot(songs, aes(x='<x>'))`<br>\n",
    "`plot + geom_histogram(bins=40)`<br>\n",
    "\n",
    "A more detailed version:<br>\n",
    "`(`<br>\n",
    "&emsp;&emsp;`ggplot(songs, aes(x='<x>')) +`<br>\n",
    "&emsp;&emsp;`geom_histogram(bins=40, color='<color>', fill='<fill>', size='<outline thickness>', alpha=<transparency, 0-1>) +`<br>\n",
    "&emsp;&emsp;`theme(figure_size=(6, 4), dpi=60) +`<br> \n",
    "&emsp;&emsp;`labs(x='<x>', y='count', title='<title>')`<br>\n",
    "`).draw()`\n",
    "\n",
    "[Excellent tutorial on plotnine](https://realpython.com/ggplot-python/)."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Minimal version\n",
    "plot = ggplot(songs, aes(x='Duration'))\n",
    "plot += theme(figure_size=(5, 3), dpi=60)\n",
    "plot += geom_histogram(bins=80, color='grey', fill='yellow')\n",
    "plot\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "To avoid the annoying text output like `<ggplot: (177159008578)>` under the plot, use the following syntax:\n",
    "\n",
    "`(`<br>\n",
    "&emsp;&emsp;`ggplot(<pd.df>, aes(x='<x>')) +`<br>\n",
    "&emsp;&emsp;`geom_histogram(bins=40, color='<color>', fill='<fill>', size='<outline thickness>', alpha=<transparency, 0-1>) +`<br>\n",
    "&emsp;&emsp;`theme(figure_size=(6, 4), dpi=60) +`<br> \n",
    "&emsp;&emsp;`labs(x='<x>', y='count', title='<title>')`<br>\n",
    "`).draw()`"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "(\n",
    "    ggplot(songs, aes(x='Duration')) +\n",
    "    geom_histogram(bins=40, color='grey', fill='yellow', size=0.5, alpha=0.8) + \n",
    "    theme(figure_size=(5, 3), dpi=60) + \n",
    "    labs(x='duration', y='count', title='Song duration histogram')\n",
    ").draw()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Bar graph"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Read the dataset (`'../data/brit_visualization_duration_int.csv'`) and make some minor transformations.\n",
    "\n",
    "`pd.read_csv()` returns a `pd.DataFrame` object.\n",
    "\n",
    "As for specifying the path of the dataset properly, see [this](https://stackoverflow.com/questions/35384358/how-to-open-my-files-in-data-folder-with-pandas-using-relative-path) (more specifically, **both** [this](https://stackoverflow.com/a/35384414/1899061) and [this](https://stackoverflow.com/a/43600253/1899061))."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Get the songs as a pd.DataFrame object from 'data/brit_visualization_duration_int.csv', or from\n",
    "# '../data/brit_visualization_duration_int.csv', or '../../data/brit_visualization_duration_int.csv', or ..., \n",
    "# depending on where the csv file is located\n",
    "songs = pd.read_csv('../data/brit_visualization_duration_int.csv')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "How many powerful, energetic, intense, loud, and possibly anthemic songs did each British Invasion band released during the period of British Invasion?"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Define a new feature (column in the `songs` dataframe), `powerful`, as a combination of `energy` and `loudness` - songs with `energy` and `loudness` above the corresponding 3rd quartiles are considered powerful."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Run songs.describe() to see the 3rd quartiles\n",
    "songs.describe()\n",
    "# type(songs.describe())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Display the 3rd quartiles for selected candidate features to describe the new feature, 'poweful' \n",
    "# ('danceability', 'energy', 'liveness', 'loudness', 'tempo', 'valence', 'shake_the_audience')\n",
    "songs.describe().loc['75%', ['danceability', 'energy', 'liveness', 'loudness', 'tempo', 'valence', 'shake_the_audience']]\n",
    "# songs.describe().loc['75%', ['danceability', 'energy', 'liveness', 'loudness', 'tempo', 'valence', 'shake_the_audience']]['danceability']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define threshold values for the candidate features (3rd quartiles, i.e. '75%')\n",
    "thresholds = songs.describe().loc['75%', ['danceability', 'energy', 'liveness', 'loudness', 'tempo', 'valence', 'shake_the_audience']]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define the condition for a song to be powerful (songs with `energy` and `loudness` above the corresponding 3rd quartiles); \n",
    "# experiment with different combinations of candidate features\n",
    "\n",
    "# powerful_condition = ((songs['danceability'] > thresholds['danceability']) &\n",
    "#                       (songs['energy'] > thresholds['energy']))\n",
    "# powerful_condition = ((songs['liveness'] > thresholds['liveness']) &\n",
    "#                       (songs['energy'] > thresholds['energy']))\n",
    "powerful_condition = ((songs['loudness'] > thresholds['loudness']) &                            # !!!\n",
    "                      (songs['energy'] > thresholds['energy']))\n",
    "# powerful_condition = ((songs['loudness'] > thresholds['loudness']) &\n",
    "#                       (songs['energy'] > thresholds['energy']) &\n",
    "#                       (songs['valence'] > thresholds['valence']))\n",
    "# powerful_condition = ((songs['loudness'] > thresholds['loudness']) &\n",
    "#                       (songs['shake_the_audience'] > thresholds['shake_the_audience']))         # !\n",
    "# powerful_condition = ((songs['loudness'] > thresholds['loudness']) &\n",
    "#                       (songs['tempo'] > thresholds['tempo']))\n",
    "# powerful_condition = ((songs['energy'] > thresholds['energy']) &\n",
    "#                       (songs['valence'] > thresholds['valence']))                               # !!\n",
    "powerful_condition\n",
    "powerful_condition[powerful_condition]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define the new feature, 'powerful'\n",
    "songs['powerful'] = powerful_condition.values\n",
    "songs['powerful']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Display these powerful songs and their performers\n",
    "songs.loc[songs.powerful, ['Title', 'Performer']]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "How many British Invasion songs have been powerful, in terms of the definition of `songs.powerful` shown above?"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(songs.loc[songs.powerful, ['Title', 'Performer']])",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<u>Save this version as a new *.csv* file, for use in the subsequent examples.</u> (`<pd.df>.to_csv('<path>')`)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "songs.to_csv('../data/brit_visualization_powerful.csv', index=False)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "###### Preparing the data for plotting the bar graph"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Group the data - group the songs by performers."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "songs_by_performer = songs.groupby('Performer')",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Use `get_group(<performer>)` to get all songs by a selected performer and `value_counts()` over the resulting group's `powerful` column (showing the `True` and `False` subgroups). This is a precursor to creating the data for the y-axis of the bar graph."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "songs_by_performer.get_group('The Animals')\n",
    "# songs_by_performer.get_group('The Animals').value_counts('powerful')\n",
    "songs_by_performer.get_group('The Animals').powerful.value_counts()\n",
    "# songs_by_performer.get_group('The Animals').powerful.value_counts()[False]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Build the data to plot by extracting relevant items from each group."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "For x-axis, use `unique()` over the `Performer` column, and then optionally `list()` over the resulting array to make the list of performers."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "performers = songs.Performer.unique()\n",
    "performers = list(performers)\n",
    "performers"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "For y-axis, create the lists of the numbers of powerful songs (`powerful`) and of the other ones (`not_powerful`).\n",
    "(Start from two empty lists. Loop over the list of performers created in the previous step, `get_group()` for each performer and append the `value_counts()[True]` of the `powerful` column of the current performer (`p['powerful']`) to `powerful` if any of `p['powerful']` has the value `True`, otherwise append 0. Do the similar thing for `not_powerful`. Display both lists in the end to double-check the result.)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "powerful = []\n",
    "not_powerful = []\n",
    "for p in performers:\n",
    "    s = songs_by_performer.get_group(p)\n",
    "    powerful.append(s.powerful.value_counts()[True] if any(s.powerful) else 0)\n",
    "    not_powerful.append(s.powerful.value_counts()[False] if not all(s.powerful) else 0)\n",
    "print(powerful)\n",
    "print(not_powerful)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "And now plot the bar graph. Based on the second example from [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.bar.html) (using `<pd.df>.plot.bar()`, not Matplotlib or Seaborn).\n",
    "For a complete list of parameters used in `**kwargs`, see [this](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.html).\n",
    "For a list of named colors (Matplotlib named colors), see [here](https://matplotlib.org/stable/gallery/color/named_colors.html#css-colors)."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "First create an auxiliary dataframe to use for plotting. Use `pwerful` and `not_powerful` as the columns, <u>and the list of performers created above as the index of the dataframe</u>."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# # The role-model example from https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.bar.html\n",
    "# speed = [0.1, 17.5, 40, 48, 52, 69, 88]\n",
    "# lifespan = [2, 8, 70, 1.5, 25, 12, 28]\n",
    "# index = ['snail', 'pig', 'elephant', 'rabbit', 'giraffe', 'coyote', 'horse']\n",
    "# df = pd.DataFrame({'speed': speed, 'lifespan': lifespan}, index=index)\n",
    "\n",
    "df = pd.DataFrame({'powerful': powerful, 'not_powerful': not_powerful}, index=performers)\n",
    "df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "###### Alternative 1 - plot the bargraph using Pandas (`<pd.df>.plot.bar()`)\n",
    "\n",
    "[Pandas bargraph example](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.bar.html)\n",
    "\n",
    "Use `ax = <pd.df>.plot.bar()` to plot the bargraph.\n",
    "\n",
    "Relevant parameters:\n",
    "- `figsize=(<width>, <height>)` (e.g., (6, 6))\n",
    "- `rot=<rotation angle [degrees]>` for the x-axis labels\n",
    "- `ylim=(<from>, <to>)`\n",
    "- `color={'powerful': 'limegreen', 'not_powerful': 'navajowhite'}` (for a list of Matplotlib named colors, see [here](https://matplotlib.org/stable/gallery/color/named_colors.html#css-colors))\n",
    "- `edgecolor='<color of bin lines>'`\n",
    "- `title='<title>'`\n",
    "- `xlabel='<xlabel>'`\n",
    "- `ylabel='<ylabel>'`\n",
    "- `fontsize=<fontsize>` (for all text; suitable fontsizes are 10, 12,...)\n",
    "- `stacked=True` (the bins for the same x-axis value stacked on top of one another)\n",
    "\n",
    "The returned value (`ax`) is usually unnecessary and can be omitted.\n",
    "\n",
    "It is <b>a very good idea</b> to also use `plt.tight_layout()` <b>after</b> `<pd.df>.plot.bar()` to avoid cutoffs at the bottom of the figure.  "
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df.plot.bar(figsize=(6, 6), rot=90, ylim=(0, 100), color={'powerful': 'limegreen', 'not_powerful': 'navajowhite'}, edgecolor='grey',\n",
    "            title='Powerful songs of the British Invasion', xlabel='band', ylabel='count', fontsize=6, stacked=True);\n",
    "plt.tight_layout()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "###### Alternative 2 - plot the bargraph using Seaborn (`sb.countplot()`)\n",
    "\n",
    "Use `ax = sb.countplot()` to plot the bargraph.\n",
    "\n",
    "Relevant parameters:\n",
    "- `data=<pd.df>`\n",
    "- `x='<column 1>'` (e.g., 'Performer')\n",
    "- `hue='<column 2>'` (e.g., 'powerful`)\n",
    "- `palette='<palette>'` (e.g., 'Set2'; it is also possible to define custom palletes using Hex codes, e.g. `palette=['#432371','#FAAE7B']`)\n",
    "- `dodge=False` to make the bargraph stacked\n",
    "\n",
    "If necessary, use `plt.xticks(rotation=90)` before `sb.countplot()`.\n",
    "\n",
    "Note that `ax = sb.countplot()` returns a `pd.Axes` object, so after the call to `ax = sb.countplot()` all `pd.Axes` methods can be called (like `ax.set_title(title='<title>'`, `ax.set_ylim(...)`, etc.). "
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(12, 8), facecolor='navajowhite')\n",
    "plt.xticks(rotation=90)\n",
    "# sb.countplot(songs, x='Performer', hue='powerful', palette='viridis', dodge=False).set(title='Powerful songs', );\n",
    "ax = sb.countplot(songs, x='Performer', hue='powerful', palette=['#9fbf0d', '#db145a'], dodge=False)\n",
    "ax.set_title('Powerful songs', fontsize=20)\n",
    "ax.set_ylim(0, 100);"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### Box plot\n",
    "[Seaborn boxplot example](https://seaborn.pydata.org/generated/seaborn.boxplot.html) (used here as the role model)\n",
    "\n",
    "For Seaborn color palette names see [this](https://seaborn.pydata.org/generated/seaborn.color_palette.html#seaborn.color_palette) or [this](https://10xsoft.org/courses/data-analysis/mastering-data-visualization-with-python/section-4-data-visualization-using-seaborn/colour-palettes-seaborn/). To list the names of some ('quantitative') Seaborn color palettes, use `sb.palettes.SEABORN_PALETTES.keys()` (see [this](https://10xsoft.org/courses/data-analysis/mastering-data-visualization-with-python/section-4-data-visualization-using-seaborn/colour-palettes-seaborn/) and [this](https://www.codecademy.com/article/seaborn-design-ii) for additional named palettes)."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Read the dataset (`'data/brit_visualization_duration_int.csv'`).\n",
    "\n",
    "`pd.read_csv()` returns a `pd.DataFrame` object.\n",
    "\n",
    "As for specifying the path of the dataset properly, see [this](https://stackoverflow.com/questions/35384358/how-to-open-my-files-in-data-folder-with-pandas-using-relative-path) (more specifically, **both** [this](https://stackoverflow.com/a/35384414/1899061) and [this](https://stackoverflow.com/a/43600253/1899061))."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Get the songs as a pd.DataFrame object from 'data/brit_visualization_duration_int.csv', or from\n",
    "# '../data/brit_visualization_duration_int.csv', or '../../data/brit_visualization_duration_int.csv', or ..., depending on where the csv file is located\n",
    "songs = pd.read_csv('../data/brit_visualization_duration_int.csv')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Use `sb.boxplot()` to plot some boxplots.\n",
    "\n",
    "For a single-column boxplot, relevant parameters are `y=<pd.df>['column']` (for 'vertical' boxplot) or `x=<pd.df>['column']` (for 'horizontal' boxplot), and `palette='<palette>'` (e.g., 'Set3', 'pastel', ...; see the links above for other named color palettes). <u>Note that in case `palette` is used, it is also necessary to use `hue=<n>`, where `<n>` can be any value, e.g. 1</u>.\n",
    "\n",
    "For a multiple-column boxplot, relevant parameters are `data=<pd.df>[['column1', 'column2',...]]`, `orient='v'` (for 'vertical' boxplot) and `palette='<palette>'`. No `hue` is needed, no `legend`."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# display(sb.palettes.SEABORN_PALETTES.keys())\n",
    "\n",
    "# For a single column (e.g., Duration)\n",
    "# # sb.boxplot(x=songs.Duration, palette='Set1');\n",
    "\n",
    "plt.figure(layout='constrained', facecolor='navajowhite', figsize=(3.5, 2), )\n",
    "# sb.boxplot(y=songs.Duration, palette='Set1', hue=1, legend=False)\n",
    "\n",
    "# # Alternatively\n",
    "# sb.boxplot(data=songs, y='Duration', palette='Set1', hue=1, legend=False)\n",
    "# plt.tight_layout()\n",
    "\n",
    "# For multiple columns (e.g., energy and acousticness)\n",
    "sb.boxplot(data=songs[['acousticness', 'energy']], palette='Set3');\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### Violin plot\n",
    "[Seaborn violin plot example](https://seaborn.pydata.org/generated/seaborn.violinplot.html)\n",
    "\n",
    "Combines box plot and density plot. Based on [this](https://stackoverflow.com/questions/46134113/seaborn-violin-plot-from-pandas-dataframe-each-column-its-own-separate-violin-p) and [this](https://seaborn.pydata.org/generated/seaborn.violinplot.html)."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Read the dataset (`'../data/brit_visualization_duration_int.csv'`).\n",
    "\n",
    "`pd.read_csv()` returns a `pd.DataFrame` object.\n",
    "\n",
    "As for specifying the path of the dataset properly, see [this](https://stackoverflow.com/questions/35384358/how-to-open-my-files-in-data-folder-with-pandas-using-relative-path) (more specifically, **both** [this](https://stackoverflow.com/a/35384414/1899061) and [this](https://stackoverflow.com/a/43600253/1899061))."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Get the songs as a pd.DataFrame object from ''../data/brit_visualization_duration_int.csv'', or from\n",
    "# '../data/brit_visualization_duration_int.csv', or '../../data/brit_visualization_duration_int.csv', or ..., depending on where the csv file is located\n",
    "songs = pd.read_csv('../data/brit_visualization_duration_int.csv')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Use `sb.violinplot()` like: `x=<pd.df>.loc[<index>, '<column for x-axis>']`, `sb.violinplot(data=<pd.df>, x=x, y=<pd.df>['<column for y-axis>'], hue=x, palette='<palette>', legend=False)`.\n",
    "\n",
    "For example, if the violin plot should represent density/boxplot diagram of song `Duration` in certain `Year`s, then `<column for x-axis>` is `Year` and `<column for y-axis>` is `Duration`. Good values for `'<palette>'` are, e.g., 'Set3', 'pastel',...).\n",
    "\n",
    "It is a good practice to set the `x` parameter directly before the call to `sb.violinplot()`, and then use `x=x` in `sb.violinplot()`. Using `x=<pd.df>.loc[<index>, '<column for x-axis>']` within the call to `sb.violinplot()` (like call to `sb.violinplot(x=<pd.df>.loc[<index>, '<column for x-axis>'], y=..., ...)`) might generate an error."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(layout='constrained', facecolor='navajowhite', figsize=(10, 7), )\n",
    "\n",
    "x=songs.loc[songs.Year < 1968, 'Year']\n",
    "sb.violinplot(songs, x=x, y=songs.Duration, hue=x, palette='Set1', legend=False);"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### Heat map\n",
    "[Seaborn heat map example](https://seaborn.pydata.org/generated/seaborn.heatmap.html) (used here as the role model)\n",
    "\n",
    "To create a heatmap, create the corresponding pivot table first. [An intuitive visual explanation of pivot tables](https://support.microsoft.com/en-us/office/overview-of-pivottables-and-pivotcharts-527c8fa3-02c0-445a-a2db-7794676bce96#:~:text=A%20PivotTable%20is%20an%20interactive,unanticipated%20questions%20about%20your%20data.) (start from [this raw table](https://support.microsoft.com/en-us/office/create-a-pivottable-to-analyze-worksheet-data-a9a84538-bfe9-40a9-a8e9-f99134456576), and then see [the corresponding pivot table](https://support.microsoft.com/en-us/office/overview-of-pivottables-and-pivotcharts-527c8fa3-02c0-445a-a2db-7794676bce96#:~:text=A%20PivotTable%20is%20an%20interactive,unanticipated%20questions%20about%20your%20data.) (expand <em>About Pivot Tables</em>)).\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Read the dataset (`'../data/brit_visualization_duration_int.csv'`).\n",
    "\n",
    "`pd.read_csv()` returns a `pd.DataFrame` object.\n",
    "\n",
    "As for specifying the path of the dataset properly, see [this](https://stackoverflow.com/questions/35384358/how-to-open-my-files-in-data-folder-with-pandas-using-relative-path) (more specifically, **both** [this](https://stackoverflow.com/a/35384414/1899061) and [this](https://stackoverflow.com/a/43600253/1899061))."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Get the songs as a pd.DataFrame object from ''../data/brit_visualization_duration_int.csv'', or from\n",
    "# '../data/brit_visualization_duration_int.csv', or '../../data/brit_visualization_duration_int.csv', or ..., depending on where the csv file is located\n",
    "songs = pd.read_csv('../data/brit_visualization_duration_int.csv')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The idea: categorize songs according to their *valence*."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# # Plot the density function for 'valence'\n",
    "# from plotnine import geom_density\n",
    "# (\n",
    "#     ggplot(songs, aes(x='valence')) +\n",
    "#     geom_density()\n",
    "# ).draw()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "###### Alternative 1 - using `pd.qcut()`\n",
    "Create a new column in the dataframe, e.g. `valence_category`, using `pd.qcut()` function to split the entire range of `songs.valence` values into five equally sized subranges, `Very Low` to `Very High` (with ~equal number of elements in each subrange): `songs['valence_category'] = pd.qcut(songs.valence, q=5, labels=['Very Low', 'Low', 'Medium', 'High', 'Very High'])`."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create the new column\n",
    "songs['valence_category'] = pd.qcut(songs.valence, q=5, labels=['Very Low', 'Low', 'Medium', 'High', 'Very High'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check the type of its values using type(<pd.df>.<new column>.values)\n",
    "type(songs.valence_category.values)\n",
    "# Display the categories in the new column using <pd.df>.<new column>.cat.categories\n",
    "songs.valence_category.cat.categories"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check value_counts() for 'valence_category'\n",
    "songs['valence_category'].value_counts()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "###### Alternative 2 - using `pd.cut()`\n",
    "Create a new column in the dataframe, e.g. `valence_category`, using `pd.cut()` function to split the entire range of `songs.valence` values into five equally *spaced* subranges, `Very Low` to `Very High` (with  generally *unequal* number of elements in each subrange): `songs['valence_category'] = pd.cut(songs.valence, bins=[<bin edges>], labels=['Very Low', 'Low', 'Medium', 'High', 'Very High'], include_lowest=True)`. Note that there one more `<bin edges>` than bins (defined in `labels`). \n",
    "\n",
    "Note that the ranges of values in the bins are defined as `(...]`. Thus make sure to include `include_lowest=True` in the call to `pd.cut()` to include the lowest value in the first bin (i.e., to get its range as `[...]`, not as `(...]`). The highest value in the last bin is always included."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Extract mean, median and other values of valence as v_mean, v_median, etc. from songs.valence.describe().values, to be used as bin edges\n",
    "songs.describe().loc[:, 'valence']\n",
    "_, v_mean, _, v_min, v_q1, v_median, v_q3, v_max = songs.describe().loc[:, 'valence']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define the list of bin edges (v_min, v_mean, v_median, etc.)\n",
    "bin_edges=[v_min, v_q1, v_mean, v_median, v_q3, v_max]\n",
    "# Dafine the list of bin labels ('Very Low','Low', etc.)\n",
    "labels=['Very Low','Low','Medium','High','Very High']\n",
    "# Create 'valence_category' using pd.cut(songs['valence'], ...)\n",
    "songs['valence_category'] = pd.cut(songs['valence'], bins=bin_edges, labels=labels, include_lowest=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check value_counts() for 'valence_category'\n",
    "songs['valence_category'].value_counts()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "###### Alternative 3 - create `valence` categories manually\n",
    "For example, split the range of `valence` to five subranges, `Very Low` to `Very High` according to the following criteria: \n",
    "- `Very Low` is the *valence* from 0 to the first quartile (`songs.valence.describe()['25%']`)\n",
    "- `Low` is the *valence* from the first quartile to the mean value (`songs.valence.describe()['mean']`), since the mean value is lower than the median value\n",
    "- `Medium` is the *valence* from the mean value to the median value (`songs.valence.describe()['50%']`)\n",
    "- `High` is the *valence* from the median value to the third quartile (`songs.valence.describe()['75%']`)\n",
    "- `Very High` is the *valence* from the third quartile to 1"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# # Extract mean, median and other values of valence as v_mean, v_median, etc. from songs.valence.describe().values\n",
    "# songs.valence.describe()\n",
    "# _, v_mean, _, _, v_q1, v_median, v_q3, _ = songs.valence.describe().values"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Insert a new column, e.g. `valence_category` and set it to the default value `Medium`. Then split the range of `valence` to five subranges, `Very Low` to `Very High` (find the `max()` of `valence` first). Each such a subrange is actually an index of selected songs, based on the value of `valence` (e.g., `very_low = songs['valence'] < 10`). Then use `<pd.df>.loc[<index of selected observations>, <relevant column>]` to change the default value `Medium` where appropriate (e.g., `songs.loc[very_low, 'valence_category'] = 'Very Low'`)."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# # Insert a new column, e.g. valence_category and set it to the default value 'Medium'. \n",
    "# # Then split the range of valence to five subranges, 'Very Low' to 'Very High.\n",
    "# songs['valence_category'] = 'Medium'\n",
    "# songs.loc[songs.valence <= v_q1, 'valence_category'] = 'Very Low'\n",
    "# songs.loc[(songs.valence > v_q1) & (songs.valence <= v_mean), 'valence_category'] = 'Low'\n",
    "# songs.loc[(songs.valence > v_median) & (songs.valence <= v_q3), 'valence_category'] = 'High'\n",
    "# songs.loc[songs.valence > v_q3, 'valence_category'] = 'Very High'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<u>Save this version as a new *.csv* file, for possible use in other examples.</u> (`<pd.df>.to_csv('<path>')`)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "songs.to_csv('../data/brit_visualization_valence_categories.csv', index=False)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Rearrange the categories of `valence_category` to make the output natural.\n",
    "Use `<pd.df>['<column>'] = pd.Categorical(<pd.df>[<column>], categories=['<cat1>, <cat2>, ...'], ordered=True)`. In this example, order categories from `Very High` to `Very Low`."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "songs.valence_category = pd.Categorical(songs.valence_category, categories=['Very High', 'High', 'Medium', 'Low', 'Very Low'], ordered=True)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Create a suitable pivot table. Use `<pivot table> = <pd.df>.pivot_table(values='<column with values to show on the heatmap>', index='<categorical index>', columns='<column>')`\n",
    "- `values`: e.g. `obscene` or `tempo`\n",
    "- `index`: to be shown on y-axis, e.g. `valence_category`\n",
    "- `columns`: to be shown on x-axis, e.g. `Year`"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# pivot_table = songs.pivot_table(values='energy', index='valence_category', columns='Year')\n",
    "pivot_table = songs.pivot_table(values='tempo', index='valence_category', columns='Year')\n",
    "pivot_table"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Plot the corresponding heatmap. Based on [this](https://pythonbasics.org/seaborn-heatmap/), [this](https://seaborn.pydata.org/generated/seaborn.heatmap.html), and [this](https://stackoverflow.com/a/29648332/1899061).\n",
    "\n",
    "It is often a good idea to change the default figure size first, using `sb.set_theme(rc={'figure.figsize': (<x_size>, <y_size>)})`, to avoid cluttering on the heatmap (alternatively, use something like `plt.figure(layout='constrained', facecolor='navajowhite', figsize=(5, 3.5))`). Here `rc` stands for 'run command' - essentially, configurations which will execute when running the code. Experiment with `(<x_size>, <y_size>)`. The values that have worked well in this example: (15.7, 5.27).\n",
    "\n",
    "Then use `sb.heatmap(data=<pivot table>, annot=True, fmt='<format string>', cmap='<color map>');`\n",
    "- `data=<pivot table>`: the pivot table created in the previous step\n",
    "- `annot=True`: annotate heatmap cells with values\n",
    "- `fmt='<format_string>'`: for example, use `'.0f'` to show int values in annotations, not scientific notation (`'g'` for using mixed int and float annotations)\n",
    "- `cmap='<color map>'`: color map (see [this](https://10xsoft.org/courses/data-analysis/mastering-data-visualization-with-python/section-4-data-visualization-using-seaborn/colour-palettes-seaborn/)); a good one is `viridis`\n",
    "\n",
    "To set the title for the heatmap, or to change the axes labels, use (<b>AFTER</b> the call to `sb.heatmap()`!) something like:\n",
    "\n",
    "`plt.title('<title>', loc='left', color='<color>', alpha=0.4, size=14)`<br>\n",
    "`plt.xlabel('<xlabel>', size=<font size>, color='<color>')`<br>\n",
    "`plt.ylabel('<ylabel>', size=<font size>, color='<color>')`<br>\n",
    "`plt.show()`    # it's a must"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# sb.set_theme(rc={'figure.figsize': (15.7, 5.27)})\n",
    "plt.figure(layout='constrained', facecolor='navajowhite', figsize=(5, 3.5))\n",
    "sb.heatmap(data=pivot_table, annot=True, fmt='.2f', cmap='viridis');\n",
    "# plt.title('Heatmap', loc='left', color='red', alpha=0.4, size=14)\n",
    "# plt.xlabel('Year', size=10)\n",
    "# plt.ylabel('Valence', size=10)\n",
    "# plt.xticks(size=6, color='red')\n",
    "# plt.yticks(size=6, color='red')\n",
    "# plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### A fancier example\n",
    "Average duration of songs over the years, represented as circles with sizes proportional to the numbers of songs."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# songs = pd.read_csv('../data/brit_visualization_valence_categories.csv')\n",
    "# songs_by_year = songs.groupby('Year')\n",
    "# years = np.sort(songs.Year.unique())\n",
    "# years\n",
    "# \n",
    "# avg_duration = []\n",
    "# for year in years:\n",
    "#     avg_duration.append(np.mean(songs_by_year.get_group(year)['Duration']))\n",
    "# avg_duration = np.array(avg_duration)\n",
    "# \n",
    "# rng = np.random.RandomState(370)\n",
    "# \n",
    "# colors = rng.choice(100, size=len(years), replace=False)                    # random sample, no duplicates\n",
    "# # display(colors)\n",
    "# \n",
    "# sizes = []\n",
    "# for year in years:\n",
    "#     sizes.append(len(songs_by_year.get_group(year)) * 100)                  # sizes proportional to the numbers of songs\n",
    "# \n",
    "# # plt.title('Song duration over the years', fontdict={'size': 20})\n",
    "# # plt.xlabel('Year')\n",
    "# # plt.ylabel('Duration')\n",
    "# # plt.xlim(1963, 1968)\n",
    "# # plt.ticklabel_format(useOffset=False)\n",
    "# # plt.scatter(years, avg_duration,\n",
    "# #             c=colors, s=sizes, alpha=0.3,                                   # alpha: the level of transparency\n",
    "# #             cmap='Set1')                                                    # cmap: a pre-defined color map\n",
    "# # plt.colorbar();                                                             # show color scale\n",
    "# # \n",
    "# # # Alternatively, but without showing the colorbar\n",
    "# # ax = plt.axes()\n",
    "# # ax.set(xlabel='Year', ylabel='Duration', xlim=(1963, 1968),\n",
    "# #        title='Song duration over the years')\n",
    "# # plt.ticklabel_format(useOffset=False)\n",
    "# # ax.scatter(years, avg_duration,\n",
    "# #            c=colors, s=sizes, alpha=0.3,                                    # alpha: the level of transparency\n",
    "# #            cmap='Set1');                                                    # cmap: a pre-defined color map"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
